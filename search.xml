<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MNIST数据集手写数字识别</title>
      <link href="/2022/05/09/mnist%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>/2022/05/09/mnist%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="MNIST数据集手写数字识别"><a href="#MNIST数据集手写数字识别" class="headerlink" title="MNIST数据集手写数字识别"></a>MNIST数据集手写数字识别</h1><h2 id="1-神经网络架构"><a href="#1-神经网络架构" class="headerlink" title="1. 神经网络架构"></a>1. 神经网络架构</h2><p>​        对于识别分类MNIST数据集中手写数字的问题，由于识别分类任务相对简单，我没有采用CNN网络，而是设计了由三层全连接层构成的神经网络。</p><p>​        此模型由三层全连接网络组成，输入层的大小为784，即输入图片大小（28 * 28），第一层隐藏层网络结点为100，第二层为100，第三层为输出层，由于有10个不同结果，采用Softmax，有10个节点，这些参数都可以在代码中基于训练结果进行调整。上图展示了大致的网络架构，但由于图片大小有限，具体节点数量与图片中的数量不同。</p><p><img src="/network.png" class="lazyload" data-srcset="/network.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><h2 id="2-MNIST数据读取"><a href="#2-MNIST数据读取" class="headerlink" title="2. MNIST数据读取"></a>2. MNIST数据读取</h2><p>MNIST数据集可以在其官网下载，本文中采用Tensorflow中data_load()函数直接读取MNIST数据集</p><h2 id="3-代码部分"><a href="#3-代码部分" class="headerlink" title="3. 代码部分"></a>3. 代码部分</h2><p>部分注释由copilot辅助生成，可能存在问题</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. MNIST数据集读取及预处理（借助Tensorflow中的load_data））</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets.mnist <span class="keyword">import</span> load_data</span><br><span class="line">(train_x, train_y), (test_x, test_y) = load_data()  <span class="comment"># 利用Tensorflow中的MNIST数据集读取函数读取数据集</span></span><br><span class="line">train_x, test_x = train_x / <span class="number">255</span>, test_x / <span class="number">255</span>  <span class="comment"># 归一化</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 基础函数</span></span><br><span class="line"><span class="comment"># 2.1 隐含层的激活函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 输出层的激活函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">y</span>):</span></span><br><span class="line">    c = np.<span class="built_in">max</span>(y)</span><br><span class="line">    y = y - c</span><br><span class="line">    <span class="built_in">sum</span> = np.<span class="built_in">sum</span>(np.exp(y))</span><br><span class="line">    <span class="keyword">return</span> np.exp(y) / <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3 定义均方误差损失函数定义</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">y_pre, y_grtru</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">sum</span>(np.square(y_pre - y_grtru))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.4 定义交叉熵损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_loss</span>(<span class="params">y_pre, y_grtru</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -np.<span class="built_in">sum</span>(y_grtru * np.log(y_pre) + (<span class="number">1</span> - y_grtru) * np.log(<span class="number">1</span> - y_pre))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.5 数据集转置函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_transpose</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    y_t = np.zeros((y.size, <span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, y.size):</span><br><span class="line">        y_t[i, <span class="number">0</span>, y[i]] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x.reshape(y.size, <span class="number">1</span>, x[<span class="number">0</span>].size), y_t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.6 模型权重导入</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>(<span class="params">weight_path</span>):</span></span><br><span class="line">    h5f = h5py.File(weight_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    w1 = h5f[<span class="string">&#x27;w1&#x27;</span>][:]</span><br><span class="line">    b1 = h5f[<span class="string">&#x27;b1&#x27;</span>][:]</span><br><span class="line">    w2 = h5f[<span class="string">&#x27;w2&#x27;</span>][:]</span><br><span class="line">    b2 = h5f[<span class="string">&#x27;b2&#x27;</span>][:]</span><br><span class="line">    w3 = h5f[<span class="string">&#x27;w3&#x27;</span>][:]</span><br><span class="line">    b3 = h5f[<span class="string">&#x27;b3&#x27;</span>][:]</span><br><span class="line">    <span class="keyword">return</span> w1, w2, w3, b1, b2, b3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 网络搭建</span></span><br><span class="line"><span class="comment"># 3.1 初始化模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">genarate_model</span>():</span></span><br><span class="line">    w1 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_input, (width_input, width_net1))</span><br><span class="line">    b1 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_net1, (width_net1,))</span><br><span class="line">    w2 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_net1, (width_net1, width_net2))</span><br><span class="line">    b2 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_net2, (width_net2,))</span><br><span class="line">    w3 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_net2, (width_net2, width_net3))</span><br><span class="line">    b3 = np.random.normal(<span class="number">0</span>, <span class="number">2</span> / width_net3, (width_net3,))</span><br><span class="line">    <span class="keyword">return</span> w1, w2, w3, b1, b2, b3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 基本参数设置</span></span><br><span class="line"><span class="comment"># 网络模型结构参数</span></span><br><span class="line">width_input = <span class="number">784</span>  <span class="comment"># 输入层神经网络节点数=28*28</span></span><br><span class="line">width_net1 = <span class="number">100</span>  <span class="comment"># 第一层神经网络节点数</span></span><br><span class="line">width_net2 = <span class="number">100</span>  <span class="comment"># 第二层神经网络节点数</span></span><br><span class="line">width_net3 = <span class="number">10</span>  <span class="comment"># 输出层神经网络节点数</span></span><br><span class="line"><span class="comment"># 模型训练参数</span></span><br><span class="line">epoch = <span class="number">15</span>  <span class="comment"># 训练轮数</span></span><br><span class="line">way_dec_lr = <span class="number">1</span>  <span class="comment"># input:1 or 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">学习率更新方式，选1，表示每lr_dec_epoch轮固定按lr_dec_rate比例减少学习率</span></span><br><span class="line"><span class="string">选择2，表示记录5次学习率大小，当当前轮次loss值大于前nub次（包括本次）loss平均值</span></span><br><span class="line"><span class="string">时，学习率自动降为当前学习率0.1倍，当学习率降为last_lr时，训练终止，保存模型</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">nub = <span class="number">3</span>  <span class="comment"># 设置记录nub次loss值</span></span><br><span class="line">last_lr = <span class="number">0.0001</span>  <span class="comment"># 方式2时，最终截止学习率值</span></span><br><span class="line">learn_rate = <span class="number">0.01</span>  <span class="comment"># 默认学习率</span></span><br><span class="line">init_learn_rate = <span class="number">0.01</span>  <span class="comment"># 初始学习率</span></span><br><span class="line">lr_dec_epoch = <span class="number">10</span>  <span class="comment"># 设置每10轮更新一次学习率</span></span><br><span class="line">lr_dec_rate = <span class="number">0.5</span>  <span class="comment"># 跟新学习率倍数</span></span><br><span class="line">savepath = <span class="string">&#x27;weight4.h5&#x27;</span>  <span class="comment"># 保存模型地址</span></span><br><span class="line">loadmodel = <span class="string">&#x27;weight3.h5&#x27;</span>  <span class="comment"># 当为迁移学习时，载入模型地址（请确保本次训练模型结构与加载的模型一致）</span></span><br><span class="line">isretrain = <span class="literal">False</span>  <span class="comment"># 是否为迁移学习True or False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络输入层</span></span><br><span class="line">x = np.zeros((width_input,))</span><br><span class="line"><span class="comment"># 定义网络第一层</span></span><br><span class="line">a1 = np.zeros((width_net1,))</span><br><span class="line"><span class="comment"># 定义网络隐藏层</span></span><br><span class="line">a2 = np.zeros((width_net2,))</span><br><span class="line"><span class="comment"># 定义网络输出层</span></span><br><span class="line">y = np.zeros((width_net3,))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化nub个临时保存模型的参数,以便在早停前选取最优模型</span></span><br><span class="line">w11 = np.zeros((nub, width_input, width_net1))</span><br><span class="line">b11 = np.zeros((nub, width_net1))</span><br><span class="line">w21 = np.zeros((nub, width_net1, width_net2))</span><br><span class="line">b21 = np.zeros((nub, width_net2))</span><br><span class="line">w31 = np.zeros((nub, width_net2, width_net3))</span><br><span class="line">b31 = np.zeros((nub, width_net3))</span><br><span class="line"><span class="comment"># 模型参数生成</span></span><br><span class="line"><span class="keyword">if</span> isretrain:</span><br><span class="line">    w1, w2, w3, b1, b2, b3 = get_model(loadmodel)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    w1, w2, w3, b1, b2, b3 = genarate_model()</span><br><span class="line"><span class="comment"># 初始化参数z（其中a=sigmoid（z））</span></span><br><span class="line">z1 = np.dot(x, w1) + b1</span><br><span class="line">z2 = np.dot(a1, w2) + b2</span><br><span class="line">z3 = np.dot(a2, w3) + b3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.3 定义前向传播</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedforward</span>(<span class="params">a, w, b</span>):</span></span><br><span class="line">    <span class="keyword">return</span> sigmoid(np.dot(a, w) + b)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.4 保存模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_model</span>(<span class="params">savepath, w_1, w_2, w_3, b_1, b_2, b_3</span>):</span></span><br><span class="line">    filename = savepath</span><br><span class="line">    h5f = h5py.File(filename, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;w1&#x27;</span>, data=w_1)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;w2&#x27;</span>, data=w_2)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;w3&#x27;</span>, data=w_3)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;b1&#x27;</span>, data=b_1)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;b2&#x27;</span>, data=b_2)</span><br><span class="line">    h5f.create_dataset(<span class="string">&#x27;b3&#x27;</span>, data=b_3)</span><br><span class="line">    h5f.close</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 模型训练</span></span><br><span class="line">start_time = time.perf_counter()  <span class="comment"># 计时</span></span><br><span class="line"><span class="comment"># 初始化记录nub次loss值loss2</span></span><br><span class="line">loss2 = np.zeros((nub,))</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">train_record = []</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, epoch + <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;==================================== Epoch %d ====================================&quot;</span> % (n + <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 方式1改变学习率</span></span><br><span class="line">    <span class="keyword">if</span> way_dec_lr == <span class="number">1</span>:</span><br><span class="line">        learn_rate = init_learn_rate * lr_dec_rate ** (<span class="built_in">int</span>(n / lr_dec_epoch))  <span class="comment"># 学习率随着学习轮数指数递减</span></span><br><span class="line">    <span class="comment"># 打乱训练和测试样本</span></span><br><span class="line">    r = np.random.permutation(<span class="number">60000</span>)</span><br><span class="line">    train_x = train_x[r, :, :]</span><br><span class="line">    train_y = train_y[r]</span><br><span class="line">    start = time.perf_counter()  <span class="comment"># 计时</span></span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">60000</span>):</span><br><span class="line">        <span class="comment"># 向前传播</span></span><br><span class="line">        x = np.array(train_x[i])</span><br><span class="line">        x = x.reshape(width_input, )</span><br><span class="line">        z1 = np.dot(x, w1) + b1</span><br><span class="line">        a1 = feedforward(x, w1, b1)</span><br><span class="line">        z2 = np.dot(a1, w2) + b2</span><br><span class="line">        a2 = feedforward(a1, w2, b2)</span><br><span class="line">        z3 = np.dot(a2, w3) + b3</span><br><span class="line">        y = feedforward(a2, w3, b3)</span><br><span class="line">        y_t = np.zeros((width_net3,))</span><br><span class="line">        y_t[train_y[i]] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        eta3 = (-y_t / y + (<span class="number">1</span> - y_t) / (<span class="number">1</span> - y)) * sigmoid(z3) * (<span class="number">1</span> - sigmoid(z3))  <span class="comment"># 此为反向传播过程中中间参数，下同</span></span><br><span class="line">        eta2 = np.dot(eta3, np.transpose(w3)) * sigmoid(z2) * (<span class="number">1</span> - sigmoid(z2))</span><br><span class="line">        eta1 = np.dot(eta2, np.transpose(w2)) * sigmoid(z1) * (<span class="number">1</span> - sigmoid(z1))</span><br><span class="line">        b3 = b3 - learn_rate * eta3</span><br><span class="line">        b2 = b2 - learn_rate * eta2</span><br><span class="line">        b1 = b1 - learn_rate * eta1</span><br><span class="line">        w3 = w3 - learn_rate * np.dot(a2.reshape(width_net2, <span class="number">1</span>), eta3.reshape(<span class="number">1</span>, width_net3))  <span class="comment"># </span></span><br><span class="line">        w2 = w2 - learn_rate * np.dot(a1.reshape(width_net1, <span class="number">1</span>), eta2.reshape(<span class="number">1</span>, width_net2))</span><br><span class="line">        w1 = w1 - learn_rate * np.dot(x.reshape(width_input, <span class="number">1</span>), eta1.reshape(<span class="number">1</span>, width_net1))</span><br><span class="line">        <span class="comment"># 训练过程进度条加载</span></span><br><span class="line">        finish = <span class="string">&quot;▓&quot;</span> * (i // <span class="number">1000</span>)</span><br><span class="line">        need_do = <span class="string">&quot;-&quot;</span> * (<span class="number">60</span> - (i // <span class="number">1000</span>))</span><br><span class="line">        progress = ((i // <span class="number">1000</span>) / <span class="number">60</span>) * <span class="number">100</span></span><br><span class="line">        duration = dur = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rTraining : &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.2f&#125;s&quot;</span>.<span class="built_in">format</span>(progress, finish, need_do, dur), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">0.00005</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    loss1 = <span class="number">0</span></span><br><span class="line">    True_num = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 加载测试集，计算loss和precition</span></span><br><span class="line">    start = time.perf_counter()  <span class="comment"># 计时</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10000</span>):</span><br><span class="line">        <span class="comment"># 向前传播，计算预测结果</span></span><br><span class="line">        x = np.array(test_x[i])</span><br><span class="line">        x = x.reshape(<span class="number">1</span>, width_input)</span><br><span class="line">        y_t = np.zeros((width_net3,))</span><br><span class="line">        y_t[test_y[i]] = <span class="number">1</span></span><br><span class="line">        a1 = feedforward(x, w1, b1)</span><br><span class="line">        a2 = feedforward(a1, w2, b2)</span><br><span class="line">        y = feedforward(a2, w3, b3)</span><br><span class="line">        <span class="keyword">if</span> test_y[i] == np.argmax(y, axis=<span class="number">1</span>):  <span class="comment"># 若预测正确，则正确数 +1，计算正确率</span></span><br><span class="line">            True_num = True_num + <span class="number">1</span></span><br><span class="line">        loss1 = loss1 + cross_entropy_loss(y, y_t)</span><br><span class="line">        <span class="comment"># 测试过程进度条加载</span></span><br><span class="line">        finish = <span class="string">&quot;▓&quot;</span> * ((i + <span class="number">1</span>) // <span class="number">1000</span>)</span><br><span class="line">        need_do = <span class="string">&quot;-&quot;</span> * (<span class="number">10</span> - ((i + <span class="number">1</span>) // <span class="number">1000</span>))</span><br><span class="line">        progress = (((i + <span class="number">1</span>) // <span class="number">1000</span>) / <span class="number">10</span>) * <span class="number">100</span></span><br><span class="line">        duration = dur = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\rTesting : &#123;:^3.0f&#125;%[&#123;&#125;-&gt;&#123;&#125;]&#123;:.2f&#125;s&quot;</span>.<span class="built_in">format</span>(progress, finish, need_do, dur), end=<span class="string">&quot;&quot;</span>)</span><br><span class="line">        time.sleep(<span class="number">0.00005</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    precision = True_num / <span class="number">10000</span> * <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方式2改变学习率，利用队列方式记录连续nub次loss值</span></span><br><span class="line">    <span class="keyword">if</span> way_dec_lr == <span class="number">2</span>:</span><br><span class="line">        <span class="comment"># 临时存储模型</span></span><br><span class="line">        j = <span class="built_in">range</span>(<span class="number">1</span>, nub)</span><br><span class="line">        k = <span class="built_in">range</span>(<span class="number">0</span>, nub - <span class="number">1</span>)</span><br><span class="line">        w11[j] = w11[k]</span><br><span class="line">        b11[j] = b11[k]</span><br><span class="line">        w21[j] = w21[k]</span><br><span class="line">        b21[j] = b21[k]</span><br><span class="line">        w31[j] = w31[k]</span><br><span class="line">        w11[<span class="number">0</span>] = w1</span><br><span class="line">        b11[<span class="number">0</span>] = b1</span><br><span class="line">        w21[<span class="number">0</span>] = w2</span><br><span class="line">        b21[<span class="number">0</span>] = b2</span><br><span class="line">        w31[<span class="number">0</span>] = w3</span><br><span class="line">        b31[<span class="number">0</span>] = b3</span><br><span class="line">        loss2[j] = loss2[k]</span><br><span class="line">        loss2[<span class="number">0</span>] = loss1</span><br><span class="line">        <span class="comment"># 判断是否改变学习率</span></span><br><span class="line">        <span class="keyword">if</span> loss2[<span class="number">0</span>] &gt; np.mean(loss2) <span class="keyword">and</span> loss2[nub - <span class="number">1</span>] &gt; <span class="number">0</span>:</span><br><span class="line">            learn_rate = learn_rate * <span class="number">0.1</span></span><br><span class="line">            <span class="keyword">if</span> learn_rate &lt; last_lr:</span><br><span class="line">                save_model(savepath, w11[np.argmin(loss2)], w21[np.argmin(loss2)], w31[np.argmin(loss2)],</span><br><span class="line">                           b11[np.argmin(loss2)], b21[np.argmin(loss2)], b31[np.argmin(loss2)])</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>, n + <span class="number">1</span>, <span class="string">&quot;| Learning Rate:%.6f&quot;</span> % learn_rate, <span class="string">&quot;Loss:&quot;</span>, loss1)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Accuracy:%.2f&quot;</span> % precision, <span class="string">&#x27;%&#x27;</span>)</span><br><span class="line">                train_record.append([n + <span class="number">1</span>, loss1, precision])</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> n % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># 每10轮保存一次模型结果</span></span><br><span class="line">        save_model(savepath, w1, w2, w3, b1, b2, b3)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch:&quot;</span>, n + <span class="number">1</span>, <span class="string">&quot;| Learning Rate:%.4f&quot;</span> % learn_rate, <span class="string">&quot;Loss:&quot;</span>, loss1)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Accuracy:%.2f&quot;</span> % precision, <span class="string">&#x27;%&#x27;</span>)</span><br><span class="line">    train_record.append(precision)</span><br><span class="line">end_time = time.perf_counter() - start_time</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成！ 最终准确率为：%.2f&quot;</span> % (train_record[-<span class="number">1</span>]), <span class="string">&#x27;%&#x27;</span>, <span class="string">&quot; | 总训练时间为 ： %.3f s&quot;</span> % end_time)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 训练结果可视化</span></span><br><span class="line"><span class="comment"># 5.1 训练集loss可视化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_train_record</span>(<span class="params">train_record</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.plot(train_record)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;precision&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.2 随机抽取9张测试集图片进行可视化，观察训练模型的准确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">result_show</span>():</span></span><br><span class="line">    t_x, t_y = data_transpose(test_x, test_y)  <span class="comment"># 数据集转置</span></span><br><span class="line">    <span class="comment"># model_path = &#x27;weight4.h5&#x27;  # 可以测试指定模型</span></span><br><span class="line">    <span class="comment"># w1, w2, w3, b1, b2, b3 = get_model(model_path)</span></span><br><span class="line">    fig, ax = plt.subplots(nrows=<span class="number">3</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">10</span>, <span class="number">10</span>))  <span class="comment"># 生成3 * 3 的子图</span></span><br><span class="line">    ax = ax.flatten()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">        a = random.randint(<span class="number">0</span>, <span class="number">9999</span>)  <span class="comment"># 随机抽取10000个测试集图片中的任意一张</span></span><br><span class="line">        x = np.array(t_x[a])</span><br><span class="line">        x = x.reshape(<span class="number">1</span>, width_input)  <span class="comment"># 输入图片reshape</span></span><br><span class="line">        a1 = feedforward(x, w1, b1)  <span class="comment"># 进行向前传播，计算预测结果</span></span><br><span class="line">        a2 = feedforward(a1, w2, b2)</span><br><span class="line">        y = feedforward(a2, w3, b3)</span><br><span class="line">        predict_label = np.argmax(y, axis=<span class="number">1</span>)  <span class="comment"># 获取预测结果</span></span><br><span class="line">        ax[i].imshow(test_x[a], cmap=<span class="string">&quot;gray&quot;</span>)  <span class="comment"># 图片显示</span></span><br><span class="line">        ax[i].set_title(<span class="string">&quot;(%d) T: %d P: %d&quot;</span> % (i+<span class="number">1</span>, test_y[a], predict_label))  <span class="comment"># 将测试结果与正确结果进行可视化对比</span></span><br><span class="line">        ax[i].set_xticks([])  <span class="comment"># 删除坐标</span></span><br><span class="line">        ax[i].set_yticks([])  <span class="comment"># 删除坐标</span></span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">plot_train_record(train_record)  <span class="comment"># 训练过程可视化</span></span><br><span class="line">result_show()  <span class="comment"># 对结果进行随机检验</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-结果分析"><a href="#4-结果分析" class="headerlink" title="4. 结果分析"></a>4. 结果分析</h2><h3 id="4-1-参数设置"><a href="#4-1-参数设置" class="headerlink" title="4.1 参数设置"></a>4.1 参数设置</h3><p>​        在训练过程中，我首先设置了网络的基本参数及训练过程中的超参数。</p><p>​        对于网络架构，我设置第一层的节点数为784（即28*28输入），第二层的节点数为100.第三层的节点数为100，输出层的节点数为10，前几层的激活函数选用Sigmoid，最后一层为SoftMax</p><p>​        对于训练过程的超参数，由于我们的模型没有采用mini-batch的训练方法，每一个epoch训练的都是全部数据，因此epoch的数量可以设置的相对较小。过几次测试，模型在第8个epoch左右基本收敛，因此设置Epoch为15；采用基础的梯度下降；初始的学习率设置为0.01；选用实验过程一节中提到的第一种学习率更新方法，不采用迁移学习。</p><p>​        由于训练时间较长，为了清楚当前时刻模型的训练过程及进度，我为训练过程添加了进度条。</p><h3 id="4-2-训练过程"><a href="#4-2-训练过程" class="headerlink" title="4.2 训练过程"></a>4.2 训练过程</h3><p><img src="/epoch.png" class="lazyload" data-srcset="/epoch.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>上图展示了训练过程中准确率的变化过程。可以很明显地发现，在第8个epoch左右，模型的准确率基本保持97%左右不再变化。经过几次测试，设置epoch为15，在多次测试之后发现，模型都能在训练15个epoch之后达到97%以上的准确度，表明我们设置的网络基本参数以及训练过程的超参数基本合理，可以基本保证模型取得较高的准确率和结果。</p><p><img src="/nn_process.png" class="lazyload" data-srcset="/nn_process.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>上图展示了训练过程及训练结果，经过15个epoch的训练过程，最终取得了97.64%准确率的结果。</p><h3 id="4-3-训练结果"><a href="#4-3-训练结果" class="headerlink" title="4.3 训练结果"></a>4.3 训练结果</h3><p><img src="/nn_result.png" class="lazyload" data-srcset="/nn_result.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p><p>上图展示了我们随机抽取9张测试集图片进行预测的结果。T为其真实值（即Truth），P为其预测值（即Predict），结合图片，我们可以发现模型对于随机抽取的9张图片都取得了正确的预测结果，与最终得到的97.64%相对吻合。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git笔记</title>
      <link href="/2022/03/15/git%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/03/15/git%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Git-简介"><a href="#1-Git-简介" class="headerlink" title="1. Git 简介"></a>1. Git 简介</h2><p>Git采用分布式版本控制，每个人都拥有全部的代码。所有版本信息仓库全部同步到本地的每个用户，这样就可以在本地查看所有版本历史，可以离线在本地提交，只需在连网时push到相应的服务器或其他用户那里。由于每个用户那里保存的都是所有的版本数据，只要有一个用户的设备没有问题就可以恢复所有的数据，但这增加了本地存储空间的占用。</p><h2 id="2-Git-基本原理"><a href="#2-Git-基本原理" class="headerlink" title="2. Git 基本原理"></a>2. Git 基本原理</h2><p>Git本地有三个工作区域：工作目录（Working Directory）、暂存区(Stage/Index)、资源库(Repository或Git Directory)。如果在加上远程的git仓库(Remote Directory)就可以分为四个工作区域</p><ul><li><p>Workspace：工作区，就是你平时存放项目代码的地方</p></li><li><p>Index / Stage：暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息</p></li><li><p>Repository：仓库区（或本地仓库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本</p></li><li><p>Remote：远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换</p></li><li><p>Directory：使用Git管理的一个目录，也就是一个仓库，包含我们的工作空间和Git的管理空间。</p></li><li><p>WorkSpace：需要通过Git进行版本控制的目录和文件，这些目录和文件组成了工作空间。</p></li><li><p>.git：存放Git管理信息的目录，初始化仓库的时候自动创建。</p></li><li><p>Index/Stage：暂存区，或者叫待提交更新区，在提交进入repo之前，我们可以把所有的更新放在暂存区。</p></li><li><p>Local Repo：本地仓库，一个存放在本地的版本库；HEAD会只是当前的开发分支（branch）。</p></li><li><p>Stash：隐藏，是一个工作状态保存栈，用于保存/恢复WorkSpace中的临时状态。</p></li></ul><blockquote><p>工作流程</p></blockquote><p>git的工作流程一般是这样的：</p><p>１、在工作目录中添加、修改文件；</p><p>２、将需要进行版本管理的文件放入暂存区域；</p><p>３、将暂存区域的文件提交到git仓库。</p><blockquote><p>文件的四种状态</p></blockquote><p>版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。</p><ul><li>Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add 状态变为Staged.</li><li>Unmodify: 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为Modified. 如果使用git rm移出版本库, 则成为Untracked文件</li><li>Modified: 文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过, 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 !</li><li>Staged: 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodified状态. 执行git reset HEAD filename取消暂存, 文件状态为Modified</li></ul><h2 id="3-Git-常用命令"><a href="#3-Git-常用命令" class="headerlink" title="3. Git 常用命令"></a>3. Git 常用命令</h2><ol><li>创建全新的仓库，需要用GIT管理的项目的根目录执行：</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git init <span class="comment">#新建代码库</span></span><br></pre></td></tr></table></figure><ol><li>克隆一个远程仓库</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git clone [url]</span><br></pre></td></tr></table></figure><ol><li>查看文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看指定文件状态</span></span><br><span class="line">git status [filename]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有文件状态</span></span><br><span class="line">git status</span><br></pre></td></tr></table></figure><ol><li>改变文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将所有文件添加到暂存区</span></span><br><span class="line">git <span class="keyword">add</span><span class="bash"> .           </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交暂存区的内容到本地仓库 -m 提交消息（一般为代码修改内容，改动情况）</span></span><br><span class="line">git commit -m <span class="string">&quot;消息内容&quot;</span>    </span><br></pre></td></tr></table></figure><h2 id="4-忽略文件"><a href="#4-忽略文件" class="headerlink" title="4. 忽略文件"></a>4. 忽略文件</h2><p>有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等在主目录下建立”.gitignore”文件，此文件有如下规则：</p><ol><li>忽略文件中的空行或以井号（#）开始的行将会被忽略。</li><li>可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,…}）代表可选的字符串等。</li><li>如果名称的最前面有一个感叹号（!），表示例外规则，将不被忽略。</li><li>如果名称的最前面是一个路径分隔符（/），表示要忽略的文件在此目录下，而子目录中的文件不忽略。</li><li>如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">*.txt        <span class="comment">#忽略所有 .txt结尾的文件,这样的话上传就不会被选中！</span></span><br><span class="line">!lib.txt     <span class="comment">#但lib.txt除外</span></span><br><span class="line">/temp        <span class="comment">#仅忽略项目根目录下的TODO文件,不包括其它目录temp</span></span><br><span class="line">build/       <span class="comment">#忽略build/目录下的所有文件</span></span><br><span class="line">doc/*.txt    <span class="comment">#会忽略 doc/notes.txt 但不包括 doc/server/arch.txt</span></span><br></pre></td></tr></table></figure><h2 id="5-Git-分支"><a href="#5-Git-分支" class="headerlink" title="5. Git 分支"></a>5. Git 分支</h2><p>如果同一个文件在合并分支时都被修改了则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！</p><p>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。</p><h2 id="3-Git-常用命令-1"><a href="#3-Git-常用命令-1" class="headerlink" title="3. Git 常用命令"></a>3. Git 常用命令</h2><ol><li>创建全新的仓库，需要用GIT管理的项目的根目录执行：</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git init <span class="comment">#新建代码库</span></span><br></pre></td></tr></table></figure><ol><li>克隆一个远程仓库</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git clone [url]</span><br></pre></td></tr></table></figure><ol><li>查看文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看指定文件状态</span></span><br><span class="line">git status [filename]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有文件状态</span></span><br><span class="line">git status</span><br></pre></td></tr></table></figure><ol><li>改变文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将所有文件添加到暂存区</span></span><br><span class="line">git <span class="keyword">add</span><span class="bash"> .           </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交暂存区的内容到本地仓库 -m 提交消息（一般为代码修改内容，改动情况）</span></span><br><span class="line">git commit -m <span class="string">&quot;消息内容&quot;</span>    </span><br></pre></td></tr></table></figure><h2 id="4-忽略文件-1"><a href="#4-忽略文件-1" class="headerlink" title="4. 忽略文件"></a>4. 忽略文件</h2><p>有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等在主目录下建立”.gitignore”文件，此文件有如下规则：</p><ol><li>忽略文件中的空行或以井号（#）开始的行将会被忽略。</li><li>可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,…}）代表可选的字符串等。</li><li>如果名称的最前面有一个感叹号（!），表示例外规则，将不被忽略。</li><li>如果名称的最前面是一个路径分隔符（/），表示要忽略的文件在此目录下，而子目录中的文件不忽略。</li><li>如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment">#为注释</span></span><br><span class="line">*.txt        <span class="comment">#忽略所有 .txt结尾的文件,这样的话上传就不会被选中！</span></span><br><span class="line">!lib.txt     <span class="comment">#但lib.txt除外</span></span><br><span class="line">/temp        <span class="comment">#仅忽略项目根目录下的TODO文件,不包括其它目录temp</span></span><br><span class="line">build/       <span class="comment">#忽略build/目录下的所有文件</span></span><br><span class="line">doc/*.txt    <span class="comment">#会忽略 doc/notes.txt 但不包括 doc/server/arch.txt</span></span><br></pre></td></tr></table></figure><h2 id="5-Git-分支-1"><a href="#5-Git-分支-1" class="headerlink" title="5. Git 分支"></a>5. Git 分支</h2><p>如果同一个文件在合并分支时都被修改了则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！</p><p>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。</p><h2 id="3-Git-常用命令-2"><a href="#3-Git-常用命令-2" class="headerlink" title="3. Git 常用命令"></a>3. Git 常用命令</h2><ol><li>创建全新的仓库，需要用GIT管理的项目的根目录执行：</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git init <span class="comment">#新建代码库</span></span><br></pre></td></tr></table></figure><ol><li>克隆一个远程仓库</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line">$ git clone [url]</span><br></pre></td></tr></table></figure><ol><li>查看文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看指定文件状态</span></span><br><span class="line">git status [filename]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有文件状态</span></span><br><span class="line">git status</span><br></pre></td></tr></table></figure><ol><li>改变文件状态</li></ol><figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将所有文件添加到暂存区</span></span><br><span class="line">git <span class="keyword">add</span><span class="bash"> .           </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交暂存区的内容到本地仓库 -m 提交消息（一般为代码修改内容，改动情况）</span></span><br><span class="line">git commit -m <span class="string">&quot;消息内容&quot;</span>    </span><br></pre></td></tr></table></figure><h2 id="4-忽略文件-2"><a href="#4-忽略文件-2" class="headerlink" title="4. 忽略文件"></a>4. 忽略文件</h2><p>有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等在主目录下建立”.gitignore”文件，此文件有如下规则：</p><ol><li>忽略文件中的空行或以井号（#）开始的行将会被忽略。</li><li>可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,…}）代表可选的字符串等。</li><li>如果名称的最前面有一个感叹号（!），表示例外规则，将不被忽略。</li><li>如果名称的最前面是一个路径分隔符（/），表示要忽略的文件在此目录下，而子目录中的文件不忽略。</li><li>如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。</li></ol><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment">#为注释</span></span><br><span class="line">*.txt        <span class="comment">#忽略所有 .txt结尾的文件,这样的话上传就不会被选中！</span></span><br><span class="line">!lib.txt     <span class="comment">#但lib.txt除外</span></span><br><span class="line">/temp        <span class="comment">#仅忽略项目根目录下的TODO文件,不包括其它目录temp</span></span><br><span class="line">build/       <span class="comment">#忽略build/目录下的所有文件</span></span><br><span class="line">doc/*.txt    <span class="comment">#会忽略 doc/notes.txt 但不包括 doc/server/arch.txt</span></span><br></pre></td></tr></table></figure><h2 id="5-Git-分支-2"><a href="#5-Git-分支-2" class="headerlink" title="5. Git 分支"></a>5. Git 分支</h2><p>如果同一个文件在合并分支时都被修改了则会引起冲突：解决的办法是我们可以修改冲突文件后重新提交！选择要保留他的代码还是你的代码！</p><p>master主分支应该非常稳定，用来发布新版本，一般情况下不允许在上面工作，工作一般情况下在新建的dev分支上工作，工作完后，比如上要发布，或者说dev分支代码稳定后可以合并到主分支master上来。</p><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列出所有本地分支</span></span><br><span class="line">git branch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有远程分支</span></span><br><span class="line">git branch -r</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，但依然停留在当前分支</span></span><br><span class="line">git branch [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建一个分支，并切换到该分支</span></span><br><span class="line">git checkout -b [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并指定分支到当前分支</span></span><br><span class="line">$ git merge [branch]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除分支</span></span><br><span class="line">$ git branch -d [branch-name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">$ git push origin --delete [branch-name]</span><br><span class="line">$ git branch -dr [remote/branch]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新更新远程仓库代码到本地分支</span></span><br><span class="line">$ git pull &lt;远程库名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;</span><br><span class="line"><span class="comment"># 例子 ：</span></span><br><span class="line">$ git pull orgin ha ： ha</span><br><span class="line"></span><br><span class="line"><span class="comment"># 撤销对刚pull的分支的改动</span></span><br><span class="line">$ git checkout .</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit后 想撤销，退回上一次commit的版本</span></span><br><span class="line">$ git reset --hard HEAD^</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>改进的梯度下降法</title>
      <link href="/2022/03/15/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
      <url>/2022/03/15/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="改进的梯度下降法"><a href="#改进的梯度下降法" class="headerlink" title="改进的梯度下降法"></a>改进的梯度下降法</h1><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1. 摘要"></a>1. 摘要</h2><p>梯度下降是目前最流行的优化算法之一，也是当下Machine Learning和 Deep Learning中最常用的优化算法。目前，每一个流行的深度学习库都包含有关梯度下降的方法。梯度下降法是一种一阶优化算法。这意味着它在对参数执行更新时只考虑一阶导数。在每次迭代中，更新与目标函数*J(w)*的梯度相反方向的参数，其中梯度给出了最陡上升的方向。通过设置固定的步长（即学习率），使其沿着梯度方向下降，直至达到局部最小值。然而，由于各种原因，梯度下降法存在一定缺陷，使其在某些场景下无法具有较好的计算效率或准确性。针对这些缺陷，许多科学家提出了改进方法，让改进后的梯度下降法能够具有更好的优化效果。</p><h2 id="2-最速下降法"><a href="#2-最速下降法" class="headerlink" title="2. 最速下降法"></a>2. 最速下降法</h2><p>在介绍改进的梯度下降法之前，让我们先回顾最基本的最速下降法，这有助于使我们理解它的缺陷以及改进的角度。</p><h3 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1 原理"></a>2.1 原理</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://img-blog.csdnimg.cn/20200401101357456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzQ0ODkwNQ==,size_16,color_FFFFFF,t_70" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20200401101357456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzQ0ODkwNQ==,size_16,color_FFFFFF,t_70" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>如果函数 F(x) 在点 a 处可微且有定义，那么函数 F(x) 在 a 沿着与梯度相反的方向 -▽F(a) 下降最多。因此，如果对于 γ &gt; 0 在一个极小值时成立，那么<br>$$<br>{ \displaystyle F(\mathbf {a} )\geq F(\mathbf {b} ) }<br>$$<br>考虑到这一点，我们可以从函数 F 的局部极小值的初始估计出x0发，并考虑如下序列x0, x1, x2….使<br>$$<br>{ {x}_{n+1}={x}_n-\gamma_n \nabla F({x}_n),\ n \ge 0 }<br>$$</p><p>因此可得到</p><p>$$<br>F( {f  {x} } _ {0}\geq F( {f  {x} } _ {1})\geq F({f  {x} } _ {2})\geq ….<br>$$</p><p>如果顺利的话序列 Xn 收敛到期望的局部极小值。上方的图片展示了这一过程。</p><h3 id="2-2-代码实现"><a href="#2-2-代码实现" class="headerlink" title="2.2 代码实现"></a>2.2 代码实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchGradientDescent</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eta=<span class="number">0.01</span>, n_iter=<span class="number">1000</span>, tolerance=<span class="number">0.001</span></span>):</span></span><br><span class="line">        self.eta = eta</span><br><span class="line">        self.n_iter = n_iter</span><br><span class="line">        self.tolerance = tolerance</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        n_samples = <span class="built_in">len</span>(X)</span><br><span class="line">        X = np.c_[np.ones(n_samples), X]  <span class="comment"># 增加截距项</span></span><br><span class="line">        n_features = X.shape[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            errors = X.dot(self.theta) - y</span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * n_samples) * errors.dot(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gradient = <span class="number">1</span> / n_samples * X.T.dot(errors)</span><br><span class="line">                self.theta -= self.eta * gradient</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h2 id="3-改进的梯度下降法"><a href="#3-改进的梯度下降法" class="headerlink" title="3. 改进的梯度下降法"></a>3. 改进的梯度下降法</h2><p>虽然最速下降法在最优化上有一定的成效，但我们可以发现，这一方法收敛速度缓慢。且使用固定的学习率，在面对相对稀疏的数据时，并不具有较好的效果。面对这些问题，更多改进的梯度下降法被提出。其中具有代表性的有Momentum动量法，NAG，Adagrad，RMSProp，Adam和Nadam。在这里，我将逐一介绍这些方法，解释他们的原理，并给出相应的Python代码实现。</p><h3 id="3-1-Momentum动量法"><a href="#3-1-Momentum动量法" class="headerlink" title="3. 1 Momentum动量法"></a>3. 1 Momentum动量法</h3><h4 id="3-1-1-原理"><a href="#3-1-1-原理" class="headerlink" title="3.1.1 原理"></a>3.1.1 原理</h4><p>如果把梯度下降法想象成一个小球从山坡到山谷的过程，那么梯度下降法的小球是这样移动的：从A点开始，计算当前A点的坡度，沿着坡度最大的方向走一段路，停下到B。在B点再看一看周围坡度最大的地方，沿着这个坡度方向走一段路，再停下。确切的来说，这并不像一个球，更像是一个正在下山的盲人，每走一步都要停下来，用拐杖来来探探四周的路，再走一步停下来，周而复始，直到走到山谷。而一个真正的小球要比这聪明多了，从A点滚动到B点的时候，小球带有一定的初速度，在当前初速度下继续加速下降，小球会越滚越快，更快的奔向谷底。momentum 动量法就是模拟这一过程来加速神经网络的优化的。</p><p>回顾一下梯度下降法每次的参数更新公式：<br>$$<br>{W:=W−α∇W}\  {b : = b − α ∇ b}<br>$$<br>可以看到，每次更新仅与当前梯度值相关，并不涉及之前的梯度。而动量梯度下降法则对各个mini-batch求得的梯度▽w, ▽b使用指数加权平均得到 V_▽w，V_ ▽b，并使用新的参数更新之前的参数<br>例如，在100次梯度下降中求得的梯度序列为:<br>$$<br>{ ∇ W 1 , ∇ W 2 , ∇ W 3 . . . . . . . . . ∇ W 99 , ∇ W 100 }<br>$$<br>则其对应的动量梯度分别为：<br>$$<br>V_{\nabla W_0} = 0<br>$$</p><p>$$<br>V_{\nabla W_1} = \beta V_{\nabla W_0} + (1-\beta)\nabla W_1<br>$$</p><p>$$<br>V_{\nabla W_2} = \beta V_{\nabla W_1} + (1-\beta)\nabla W_2<br>$$</p><p>$$<br>. .\<br>.\<br>. .\<br>.\<br>. .\<br>.\<br>$$</p><p>$$<br>V_{\nabla W_{100}} = \beta V_{\nabla W_{99}} + (1-\beta)\nabla W_{100}<br>$$</p><p>使用指数加权平均之后梯度代替原梯度进行参数更新。因为每个指数加权平均后的梯度含有之前梯度的信息，动量梯度下降法因此得名。因此，我们可以得到Momentum动量法的公式：<br>$$<br>V_{dW} = \beta V_{dW} + (1-\beta) dW\<br>V_{db} = \beta V_{db} + (1 - \beta) db<br>$$</p><h4 id="3-1-2-优点"><a href="#3-1-2-优点" class="headerlink" title="3.1.2 优点"></a>3.1.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://image.jiqizhixin.com/uploads/editor/ccc319ff-dfbf-430b-bfc5-165f33db4344/image__15_.png" class="lazyload" data-srcset="https://image.jiqizhixin.com/uploads/editor/ccc319ff-dfbf-430b-bfc5-165f33db4344/image__15_.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>上图展示了Momentum动量法的SGD和没有采用Momentum法的SGD的对比，右图为采用Momentum法的结果。</p><p>通过这一图片，我们可以明显感受到Momentum动量法的优点。动量法通过用过去梯度的平均值来替换梯度，减少了震荡并大大加快了收敛速度</p><h4 id="3-1-3-代码实现"><a href="#3-1-3-代码实现" class="headerlink" title="3.1.3 代码实现"></a>3.1.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MomentumGradientDescent</span>(<span class="params">MiniBatchGradientDescent</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, gamma=<span class="number">0.9</span>, **kwargs</span>):</span></span><br><span class="line">        self.gamma = gamma                <span class="comment"># 当gamma=0时，相当于小批量随机梯度下降</span></span><br><span class="line">        <span class="built_in">super</span>(MomentumGradientDescent, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line"></span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.velocity = np.zeros_like(self.theta)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line"></span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta) - mini_y</span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)</span><br><span class="line">                self.velocity = self.velocity * self.gamma + self.eta * mini_gradient</span><br><span class="line">                self.theta -= self.velocity</span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h3 id="3-2-NAG"><a href="#3-2-NAG" class="headerlink" title="3.2 NAG"></a>3.2 NAG</h3><h4 id="3-2-1-原理"><a href="#3-2-1-原理" class="headerlink" title="3.2.1 原理"></a>3.2.1 原理</h4><p>NAG的全称是Nesterov Accelerated Gradient。NAG与Momentum动量法的方法非常相似，二者的差异主要在于计算梯度时所用的参数，一个是纯粹的θ，一个是经过速度调整后的~θ。为了便于理解其内在的差异，可以这样想象二者的作用机制：动量梯度下降是利用历史情况对当前状态进行纠偏，防止过度反应；而Nesterov加速下降则依赖于先见之明，对未来的走势进行预判，在事情发生前便进行了内部调整，避免出现极端情况。再给个不太恰当的比喻，Momentum是亡羊补牢，Nesterov是未雨绸缪。</p><p>Nesterov加速梯度下降相比于动量梯度下降的区别是，通过使用未来梯度来更新动量。即将下一次的预测梯度<br>$$<br>\nabla_\theta J(\theta-\eta\cdot m)<br>$$<br>考虑进来。其更新公式如下：<br>$$<br>\gamma\cdot m+\eta\cdot\nabla_\theta J(\theta-\gamma\cdot m)<br>$$</p><p>$$<br>\theta := \theta - m<br>$$</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://img-blog.csdnimg.cn/20200423213037508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzI5MDUyMw==,size_16,color_FFFFFF,t_70#pic_center" class="lazyload" data-srcset="https://img-blog.csdnimg.cn/20200423213037508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzI5MDUyMw==,size_16,color_FFFFFF,t_70#pic_center" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>对于起始点应用动量梯度下降，首先求得在该点处的带权梯度η*▽1 ，通过与之前动量 γ*m矢量加权，求得下一次的θ位置。对于起始点应用Nesterov加速梯度下降，首先通过先前动量求得的预测θ位置，再加上预测位置的带权梯度 γ*m</p><h4 id="3-2-2-优点"><a href="#3-2-2-优点" class="headerlink" title="3.2.2 优点"></a>3.2.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://miro.medium.com/max/1027/1*6MEi74EMyPERHlAX-x2Slw.png" class="lazyload" data-srcset="https://miro.medium.com/max/1027/1*6MEi74EMyPERHlAX-x2Slw.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>相对于动量梯度下降法，因为NAG考虑到了未来预测梯度，收敛速度更快。并且当更新幅度很大时，NAG可以抑制震荡。例如起始点在最优点的左侧， γ*m 对应的值在最优点的右侧，对于动量梯度而言，叠加 η*▽1使得迭代后的点更加远离最优点。而NAG首先跳到 γ*m对应的值，计算梯度为正，再叠加反方向的 η*▽2 ，从而达到抑制震荡的目的。</p><h4 id="3-2-3-代码实现"><a href="#3-2-3-代码实现" class="headerlink" title="3.2.3 代码实现"></a>3.2.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NesterovAccelerateGradient</span>(<span class="params">MomentumGradientDescent</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NesterovAccelerateGradient, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line"></span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.velocity = np.zeros_like(self.theta)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line"></span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta - self.gamma * self.velocity) - mini_y  </span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)</span><br><span class="line">                self.velocity = self.velocity * self.gamma + self.eta * mini_gradient</span><br><span class="line">                self.theta -= self.velocity</span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h3 id="3-3-Adagrad"><a href="#3-3-Adagrad" class="headerlink" title="3.3 Adagrad"></a>3.3 Adagrad</h3><h4 id="3-3-1-原理"><a href="#3-3-1-原理" class="headerlink" title="3.3.1 原理"></a>3.3.1 原理</h4><p>我们知道，超参数一直以来都是是困扰神经网络训练的问题之一，因为这些参数不可通过常规方法学习获得。而Adagrad就是通过自适应调整学习率的方式，来实现对梯度下降法的优化。Adagrad的全称是Adaptive Gradient Descent，即自适应的梯度下降。</p><p>在传统的方法中，对于每一个参数 θ 的训练都使用了相同的学习率α。Adagrad能够在训练中自动的对学习率进行调整，对于出现频率较低参数采用较大的α更新；相反，对于出现频率较高的参数采用较小的α更新。具体来说，每个参数的学习率会缩放各参数反比于其历史梯度平方值总和的平方根。因此，Adagrad非常适合处理稀疏数据。</p><p>Adagrad在每轮训练中对每个参数 θi 的学习率进行更新，参数更新公式如下：</p><p>$$<br>\Theta_{t+1,i} =\Theta_{t,i}- \frac{\alpha}{\sqrt{G_{t,ii}+\epsilon }}\cdot g_{t,i}<br>$$<br>其中 Gt 为对角矩阵，每个对角线位置 i, i 为对应参数θ从第1轮到第t轮梯度的平方和。ϵ是平滑项，用于避免分母为0，一般取值1e−8<br>$$<br>G _ {j,j}=\sum  _ { \tau =1 } ^ { t } g _ {\tau ,j }^{2 }<br>$$</p><h4 id="3-3-2-优点"><a href="#3-3-2-优点" class="headerlink" title="3.3.2 优点"></a>3.3.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://images.deepai.org/glossary-terms/b2cd547449264ffe829960fea5e7594d/adagrad.png" class="lazyload" data-srcset="https://images.deepai.org/glossary-terms/b2cd547449264ffe829960fea5e7594d/adagrad.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>无需手动调节学习率，通过自适应调整学习率，Adamgrad在处理稀疏数据时具有优势。</p><h4 id="3-3-3-代码实现"><a href="#3-3-3-代码实现" class="headerlink" title="3.3.3 代码实现"></a>3.3.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaptiveGradientDescent</span>(<span class="params">MiniBatchGradientDescent</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, epsilon=<span class="number">1e-6</span>, **kwargs</span>):</span></span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        <span class="built_in">super</span>(AdaptiveGradientDescent, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        gradient_sum = np.zeros(n_features)</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line"></span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta) - mini_y  </span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)  </span><br><span class="line">                gradient_sum += mini_gradient ** <span class="number">2</span></span><br><span class="line">                adj_gradient = mini_gradient / (np.sqrt(gradient_sum + self.epsilon))</span><br><span class="line">                self.theta -= self.eta * adj_gradient</span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line"></span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h3 id="3-4-RMSProp"><a href="#3-4-RMSProp" class="headerlink" title="3.4 RMSProp"></a>3.4 RMSProp</h3><h4 id="3-4-1-原理"><a href="#3-4-1-原理" class="headerlink" title="3.4.1 原理"></a>3.4.1 原理</h4><p>Adagrad存在一个缺点，在训练的中后期，分母上梯度平方的累加将会越来越大，从而梯度趋近于0，使得训练提前结束。针对这个缺点，Geoff Hinton 提出了自适应学习率方法——RMSProp。RMSdrop的全称是Root mean square prop，Adagrad会累加之前所有的梯度平方，而RMSProp采用了对历史梯度的平方和进行指数加权移动，来减缓梯度的累积效应，因此可缓解Adagrad算法学习率下降较快的问题。</p><p>首先，根据均方计算平均<br>$$<br>E[g^2]_t=0.9E[g^2]_t−1+0.1g^2_t<br>$$</p><p>公式为<br>$$<br>\Theta _ {t+1} =\Theta _ {t}- \frac{\alpha} {\sqrt{E[g^2] _ t+\epsilon } }\cdot g _ {t}<br>$$</p><h4 id="3-4-2-优点"><a href="#3-4-2-优点" class="headerlink" title="3.4.2 优点"></a>3.4.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://lh4.googleusercontent.com/D3_1rYgL8kLaOwk6vghqUo4P8zUHnf0SVaDolzGxwRBWKxGOEeKVt3QxYZoOxGsIR6bSQ5Axy1ZovfZWs8uhaK8xN48gthDm1ajRmJqEiOwHczuA_9ZkBEl3S__2VodnWMhB4d2X" class="lazyload" data-srcset="https://lh4.googleusercontent.com/D3_1rYgL8kLaOwk6vghqUo4P8zUHnf0SVaDolzGxwRBWKxGOEeKVt3QxYZoOxGsIR6bSQ5Axy1ZovfZWs8uhaK8xN48gthDm1ajRmJqEiOwHczuA_9ZkBEl3S__2VodnWMhB4d2X" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>RMSProp采用完全自适应全局学习率，有利于消除了摆动幅度大的方向，用来修正摆动幅度，使得各个维度的摆动幅度都较小。另一方面使算法具有更好的加速效果，加快了收敛速度。</p><h4 id="3-4-3-代码实现"><a href="#3-4-3-代码实现" class="headerlink" title="3.4.3 代码实现"></a>3.4.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RMSProp</span>(<span class="params">MiniBatchGradientDescent</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, gamma=<span class="number">0.9</span>, epsilon=<span class="number">1e-6</span>, **kwargs</span>):</span></span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        <span class="built_in">super</span>(RMSProp, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        gradient_exp = np.zeros(n_features)</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line"></span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta) - mini_y</span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)</span><br><span class="line">                gradient_exp = self.gamma * gradient_exp + (<span class="number">1</span> - self.gamma) * mini_gradient ** <span class="number">2</span></span><br><span class="line">                gradient_rms = np.sqrt(gradient_exp + self.epsilon)</span><br><span class="line">                self.theta -= self.eta / gradient_rms * mini_gradient</span><br><span class="line"></span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h3 id="3-5-Adam"><a href="#3-5-Adam" class="headerlink" title="3.5 Adam"></a>3.5 Adam</h3><h4 id="3-5-1-原理"><a href="#3-5-1-原理" class="headerlink" title="3.5.1 原理"></a>3.5.1 原理</h4><p>在上文我们有提到Momentum动量法和RMSProp两种方法，一种使用类似于物理中的动量来累积梯度，另一种使得收敛速度更快同时使得波动的幅度更小。那么将两种算法结合起来所取得的表现一定会更好。因此，Adam算法被提出。Adam的全称是 Adaptive Moment Estimation ，它将Momentum算法和RMSProp算法相结合。</p><p>Adam利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。它的公式如下<br>$$<br>{m_t=\beta_1 m_{t-1}+(1-\beta_1)g_t}<br>$$</p><p>$$<br>{v_t=\beta_2v_{t-1}+(1-\beta_2)g_t^2}<br>$$</p><p>$$<br>{\hat{m}_t=\frac{m_t}{1-\beta_1^t}}<br>$$</p><p>$$<br>{\hat{v}_t=\frac{v_t}{1-\beta_2^t}}\<br>$$</p><p>$$<br>{\Theta_{t+1} =\Theta_{t}- \frac{\alpha}{\sqrt{\hat{v}_t }+\epsilon }\hat{m}_t}<br>$$</p><p>其中，Mt ，Vt 分别是对梯度的一阶矩估计和二阶矩估计，可以看作对期望 E[gt], E[gt^2] 的近似；Mt_hat, Vt_hat是对 Mt, Vt 的校正，这样可以近似为对期望的无偏估计。 Adam算法的提出者建议 β1 的默认值为0.9，β2 的默认值为 0.999，epsilon 默认为 1e-8</p><p>Adam相对于RMSProp新增了两处改动。其一，Adam使用经过指数移动加权平均的梯度值来替换原始的梯度值；其二，Adam对经指数加权后的梯度值  Mt 和平方梯度值 都 Vt 进行了修正，亦即偏差修正。</p><h4 id="3-5-2-优点"><a href="#3-5-2-优点" class="headerlink" title="3.5.2 优点"></a>3.5.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://machinelearningmastery.com/wp-content/uploads/2017/05/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png" class="lazyload" data-srcset="https://machinelearningmastery.com/wp-content/uploads/2017/05/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>Adam通过结合Momentum动量法和RMSPorp法，在优化问题上具有优秀的性能。它具备高效的计算，更少的内存需求，且在面对稀疏数据时也能取得较好的效果。Adam对目标函数没有平稳要求，即loss function可以随着时间变化。除此之外，Adam能较好的处理噪音样本，并且天然具有退火效果</p><h4 id="3-5-3-代码实现"><a href="#3-5-3-代码实现" class="headerlink" title="3.5.3 代码实现"></a>3.5.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaptiveMomentEstimation</span>(<span class="params">MiniBatchGradientDescent</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, beta_1=<span class="number">0.9</span>, beta_2=<span class="number">0.999</span>, epsilon=<span class="number">1e-6</span>, **kwargs</span>):</span></span><br><span class="line">        self.beta_1 = beta_1</span><br><span class="line">        self.beta_2 = beta_2</span><br><span class="line">        self.epsilon = epsilon</span><br><span class="line">        <span class="built_in">super</span>(AdaptiveMomentEstimation, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        m_t = np.zeros(n_features)  </span><br><span class="line">        v_t = np.zeros(n_features)  </span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta) - mini_y</span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)</span><br><span class="line">                m_t = self.beta_1 * m_t + (<span class="number">1</span> - self.beta_1) * mini_gradient</span><br><span class="line">                v_t = self.beta_2 * v_t + (<span class="number">1</span> - self.beta_2) * mini_gradient ** <span class="number">2</span></span><br><span class="line">                m_t_hat = m_t / (<span class="number">1</span> - self.beta_1 ** self.i)  <span class="comment"># correction</span></span><br><span class="line">                v_t_hat = v_t / (<span class="number">1</span> - self.beta_2 ** self.i)</span><br><span class="line">                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * m_t_hat</span><br><span class="line"></span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h3 id="3-6-Nadam"><a href="#3-6-Nadam" class="headerlink" title="3.6 Nadam"></a>3.6 Nadam</h3><h4 id="3-6-1-原理"><a href="#3-6-1-原理" class="headerlink" title="3.6.1 原理"></a>3.6.1 原理</h4><p>Adam通过结合Momentum和RMSProp获得了优秀的优化效果，成为了当下最流行的梯度下降法之一。而受此启发，在Adam的基础上，加入一阶动量的积累，即结合NAG和Adam，一种新的梯度下降算法——Nadam诞生了。</p><p>它的公式如下<br>$$<br>\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon}(\beta_1\hat{m_t}+\frac{(1-\beta_1)g_t}{1-\beta^t_1})<br>$$<br>可以看出，Nadam对学习率有了更强的约束，同时对梯度的更新也有更直接的影响。一般而言，在想使用带动量的RMSprop，或者Adam的地方，大多可以使用Nadam取得更好的效果。</p><h4 id="3-6-2-优点"><a href="#3-6-2-优点" class="headerlink" title="3.6.2 优点"></a>3.6.2 优点</h4><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://peltarion.com/static/learning_rate_pa1-03.png" class="lazyload" data-srcset="https://peltarion.com/static/learning_rate_pa1-03.png" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>通过加入一阶动量的积累，Nadam对学习率有了更强的约束,同时对梯度的更新也有更直接的影响。一般而言,在想使用带动量的RMSprop或者Adam的地方,大多可以使用Nadam取得更好的效果。</p><h4 id="3-6-3-代码实现"><a href="#3-6-3-代码实现" class="headerlink" title="3.6.3 代码实现"></a>3.6.3 代码实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Nadam</span>(<span class="params">AdaptiveMomentEstimation</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Nadam, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        X = np.c_[np.ones(<span class="built_in">len</span>(X)), X]</span><br><span class="line">        n_samples, n_features = X.shape</span><br><span class="line">        self.theta = np.ones(n_features)</span><br><span class="line">        self.loss_ = [<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        m_t = np.zeros(n_features)</span><br><span class="line">        v_t = np.zeros(n_features)</span><br><span class="line"></span><br><span class="line">        self.i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> self.i &lt; self.n_iter:</span><br><span class="line">            self.i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.shuffle:</span><br><span class="line">                X, y = self._shuffle(X, y)</span><br><span class="line">            errors = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, n_samples, self.batch_size):</span><br><span class="line">                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]</span><br><span class="line">                error = mini_X.dot(self.theta) - mini_y</span><br><span class="line">                errors.append(error.dot(error))</span><br><span class="line">                mini_gradient = <span class="number">1</span> / self.batch_size * mini_X.T.dot(error)</span><br><span class="line">                m_t = self.beta_1 * m_t + (<span class="number">1</span> - self.beta_1) * mini_gradient</span><br><span class="line">                v_t = self.beta_2 * v_t + (<span class="number">1</span> - self.beta_2) * mini_gradient ** <span class="number">2</span></span><br><span class="line">                m_t_hat = m_t / (<span class="number">1</span> - self.beta_1 ** self.i)  <span class="comment"># correction</span></span><br><span class="line">                v_t_hat = v_t / (<span class="number">1</span> - self.beta_2 ** self.i)</span><br><span class="line">                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * (</span><br><span class="line">                            self.beta_1 * m_t_hat + (<span class="number">1</span> - self.beta_1) * mini_gradient / (<span class="number">1</span> - self.beta_1 ** self.i))</span><br><span class="line"></span><br><span class="line">            loss = <span class="number">1</span> / (<span class="number">2</span> * self.batch_size) * np.mean(errors)</span><br><span class="line">            delta_loss = loss - self.loss_[-<span class="number">1</span>]</span><br><span class="line">            self.loss_.append(loss)</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(delta_loss) &lt; self.tolerance:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br></pre></td></tr></table></figure><h2 id="4-不同方法的对比"><a href="#4-不同方法的对比" class="headerlink" title="4. 不同方法的对比"></a>4. 不同方法的对比</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload" src="https://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif" class="lazyload" data-srcset="https://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" style="width:400px;"/></div></div><p>在上文中，我们介绍了各种改进的梯度下降法，它们针对最速下降法存在的种种问题，提出了不同的改进策略和方法。在此，我们将总结和对比这些方法，了解它们与梯度下降法的区别和优点。</p><p>最速下降法只考虑一阶导数，它没有引入动量的概念，因此是最简单的。但它的问题是，它的下降速度很慢，有时会在沟壑的两边持续震荡，即最终得到的会是一个局部最优解。</p><p>针对最速下降法的下降速度慢和震荡幅度大的问题，Momentum动量法认为可以在梯度下降的过程中加入惯性。即在下坡时，如果发现坡度大，就利用惯性的特性提高速度。Momentum动量法在最速下降法的基础上引入了一阶动量，一阶动量是各个时刻梯度方向的指数移动平均值，约等于最近 1/(1-β)个时刻的梯度向量和的平均值。也就是说，在 t 时刻下降的方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。β 一般取0.9，这意味着当前的下降方向主由此前累积的下降方向所决定，在此基础上略微偏向当前时刻的下降方向。通过这一方法降低震幅，加快下降速度。</p><p>最速下降法存在的另一个问题是有时会在沟壑的两边持续震荡，即最终得到的会是一个局部最优解。针对这个问题，NAG提出了改进方案。我们知道在时刻 t 的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算，那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。通过这一方法，NAG减少了震荡幅度，解决了最速下降法的另一问题。</p><p>在最速下降法中，学习率是固定的。因此，我们需要不断调整学习率，这也导致算法经常出现下降过慢或错过最优点的问题。而二阶动量的出现，意味着“自适应学习率”优化算法时代的到来。通过自适应调整学习率，我们可以大幅提升梯度下降法的效果。</p><p>Adagrad, RMSProp, Adam 和 Nadam 就是这类算法的代表。其中，Adagrad 依据历史梯度平方和的平方根，自适应地调整学习率的大小，从而获得比最速下降法更好的效果。</p><p>但Adagrad也存在一些问题，因为它是单调递增的，导致学习率会单调递减至0，这可能会使得训练过程提前结束，即便后续还有数据也无法学到必要的知识。针对这一缺陷，RMSProp 提出了解决方案——不累积全部历史梯度，而只关注过去一段时间的下降梯度。这就解决了二阶动量持续累积、导致训练过程提前结束的问题。</p><p>而Adam和Nadam则是对之前几种方法的结合，综合了几种方法的优点，获得了更好的效果。Adam 就是在 RMSprop 的基础上结合了Momentum动量法并加入修正误差，随着梯度变的稀疏，Adam 比 RMSprop 效果会好。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><p>在最速下降法提出之后，不断有学者针对该方法提出改进和迭代。通过上文可以看出，许多的算法的提出都是针对前一种方法存在的缺陷进行优化和改进。不同的梯度下降法具有各自侧重点，在解决不同问题时具有各自的优越性。很难说哪一种算法具有远超其他算法的效果，往往需要我们在搭建不同模型，处理不同问题时有针对性地选择合适的算法。相对来说，Adam和Nadam这两种梯度下降方法，在目前最为流行。对于绝大多数情况，Adam和Nadam可以取得较好的效果。</p><p>如果数据是稀疏的，就用自适用方法，即 Adagrad, RMSprop, Adam 和 Nadam。RMSprop,  Adam 和 Nadam 在很多情况下的效果是相似的。整体来讲，Adam和Nadam 是最好的选择。以往很多论文里都会用最速下降法，没有考虑动量的引入。最速下降法虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点。如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法。</p><p>在流行的深度学习框架如Pytorch, Tensorflow中，都内置了这些梯度下降算法。因此，在模型搭建过程中，我们只需一行代码就可以快速地部署相应的梯度下降算法。</p><h2 id="6-参考文献"><a href="#6-参考文献" class="headerlink" title="6. 参考文献"></a>6. 参考文献</h2><ol><li>An overview of gradient descent optimization algorithms <a href="https://arxiv.org/search/cs?searchtype=author&query=Ruder,+S">Sebastian Ruder</a></li><li>Ning Qian. (1999).  On the momentum term in gradient descent learning algorithms, Neural Networks, Volume 12,  Issue 1</li><li>Sutskever, I., Martens, J., Dahl, G. &amp; Hinton, G.. (2013). On the importance of initialization and momentum in deep learning. </li><li>John Duchi, Elad Hazan, Yoram Singer. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. 12(61):2121−2159.</li><li>Geoff Hinton. (2012). Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</li><li>Diederik P. Kingma, Jimmy Ba. (2015). Adam: A Method for Stochastic Optimization</li><li>Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.</li><li>Bengio, Y., Boulanger-Lewandowski, N., &amp; Pascanu, R. (2012). Advances in Optimizing Recurrent Networks. </li><li><a href="https://zhuanlan.zhihu.com/p/77380412?utm_source=wechat_session">https://zhuanlan.zhihu.com/p/77380412?utm_source=wechat_session</a></li><li><a href="https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9">https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9</a></li><li>Dozat, T. (2016). Incorporating Nesterov Momentum into Adam. ICLR Workshop, (1), 2013–2016</li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-notes</title>
      <link href="/2021/12/04/JAVA-Notes/"/>
      <url>/2021/12/04/JAVA-Notes/</url>
      
        <content type="html"><![CDATA[<h1 id="Java-notes"><a href="#Java-notes" class="headerlink" title="Java-notes"></a>Java-notes</h1><h2 id="课内部分"><a href="#课内部分" class="headerlink" title="课内部分"></a>课内部分</h2><h3 id="Chapter-1（Java-概述）"><a href="#Chapter-1（Java-概述）" class="headerlink" title="Chapter-1（Java 概述）"></a>Chapter-1（Java 概述）</h3><ol><li>Java技术的<strong>通用性</strong>、<strong>高效性</strong>、<strong>平台移植性</strong>和<strong>安全性</strong>，使之成为网络计算的理想技术</li><li>Java语言是一种高级编程语言，它具有<strong>简单、结构中立、面向对象、可移植、分布式、高性能、多线程、健壮、动态、安全</strong>等特点</li></ol><h3 id="Chapter-2-（Java基础）"><a href="#Chapter-2-（Java基础）" class="headerlink" title="Chapter-2 （Java基础）"></a>Chapter-2 （Java基础）</h3><ol><li><strong>标识符</strong>：为程序中的各个元素进行命名，这种命名的记号，就是标识符（Identifier）</li><li><strong>标识符规则</strong>：在Java 中标识符是以字母、下划线（_）、美元符号（$）等开始的一个字符序列，不能包含运算符和一些特殊字符，如#、*等</li><li><strong>关键字</strong>：Java中所有的关键字都为小写，不允许对关键字赋予其他含义</li><li><strong>变量与常量</strong>：<ul><li>变量的命名： <code>int i; public int j;</code> </li><li>常量的命名：<code>final int k = 1;</code></li></ul></li><li><strong>变量的邻近原则</strong>：若在一个作用域中，如果有多个同名的变量可以访问，则按照“邻近”原则，在当前域中定义的变量隐藏其它同名的变量。</li><li><strong>数据类型</strong>：</li></ol><table><thead><tr><th>数据类型</th><th>所占位数</th><th>数的范围</th></tr></thead><tbody><tr><td>byte</td><td>8</td><td>-2<sup>7</sup> ~ (2<sup>7</sup>-1)</td></tr><tr><td>short</td><td>16</td><td>-2<sup>15</sup> ~ (2<sup>15</sup>-1)</td></tr><tr><td>int</td><td>32</td><td>-2<sup>31</sup> ~ (2<sup>31</sup>-1)</td></tr><tr><td>long</td><td>64</td><td>-2<sup>63</sup> ~ (2<sup>63</sup>-1)</td></tr></tbody></table><ol start="7"><li><strong>运算符</strong>：<ul><li>“%”（求模运算符）的操作数可为浮点数, 如 52.3%10=2.3</li><li>“+” 运算符可用作连接字符串；如果一个操作数是非字符串，其他操作数会自动转化为字符串，如 String s; s=”s:”+6*5</li></ul></li></ol><h3 id="Chapter-3（数组）"><a href="#Chapter-3（数组）" class="headerlink" title="Chapter-3（数组）"></a>Chapter-3（数组）</h3><ol><li><p><strong>数组的创建</strong>：</p><ul><li>Step1 定义数组 ：数组元素类型 数组名[ ]    如 <code>int num_array[];</code> </li><li>Step2 生成数组 ：数组名=new 数组元素类型[数组长度]  如 <code>num_array = new int[5];</code></li><li>Step3 初始化数组 ：使数组中的各个元素有确定的数值   如 <code>num_array[1] = 15;</code></li></ul><p>或直接将内存分配放在一个语句中： <code>int num_array[] = &#123;0, 1, 2&#125;;</code></p></li><li><p>Java定义数组时，不会为数组分配存储空间</p></li><li><p><strong>Arrays类</strong>：Arrays类提供了多个操作数组的静态方法</p><ul><li><strong>binarySearch</strong>(type[] a,type key)：使用二分搜索法在数组a中搜索指定值key</li><li><strong>equals</strong>(type[] a,type[] b)：比较两个数组是否相等</li><li><strong>sort</strong>(type[] a)：对数组a进行排序(默认升序)</li><li><strong>fill</strong> (type[] a, type val)：用一个指定的值val填充数组a</li></ul><p>例：<code>Arrays.sort(num_array);</code></p></li></ol><h3 id="Chapter-4（类和对象设计）"><a href="#Chapter-4（类和对象设计）" class="headerlink" title="Chapter-4（类和对象设计）"></a>Chapter-4（类和对象设计）</h3><ol><li><p>面向对象基础</p><ul><li>多态：类中同一名称的行为（方法）可以有多种不同的功能，或者相同的接口有多种实现方法。</li></ul></li><li><p>用户必须先<strong>定义类</strong>，并<strong>生成该类的实例</strong>，然后才能通过该实例访问其成员变量和方法。</p></li><li><p>格式：</p><p>[类修饰符] class 类名 [extends 父类名] [implements 接口名]  {</p><pre><code>           //类体，包括定义类的成员变量 和 成员方法</code></pre><p> }</p></li><li><p>包（package）：package语句必须是程序的第一条非空格、非注释语句；同一个包中，类不可以重名，但是不同的包中允许相同的类名出现</p><ul><li>格式：package pkg1[．pkg2[．pkg3…]];</li><li><strong>import：</strong> pkg1.pkg2.* （*可以导入pkg2中所有的类）</li><li><strong>import static:</strong> 用于导入指定类的某个静态成员变量 / 方法 / 或全部静态成员变量 / 方法（例如可以直接导入Math类中的变量PI）</li></ul></li><li><p>修饰符：</p></li></ol><ul><li><p><strong>Public:</strong> 使用public，意味着public之后的成员声明对每个人都是有用的；修饰类时，一个类中最多只能有一个public，且类名需要与文件名相同</p></li><li><p><strong>Private:</strong> 即便是处于同一个包内的其他类也是不可以访问private成员的，通俗说就是自己隔离了自己</p></li><li><p><strong>Protected:</strong> protected处理的是继承的概念。只有<strong>继承他的类</strong>才可以访问他的方法（与public的区别是，只有<strong>同一个包中的类才可以访问</strong>）</p></li><li><p><strong>Default:</strong> 如果类成员前没有使用public,protected,private中的任何一个修饰符，我们称它使用了缺省(default)修饰符；只有该类本身以及与该类在同一个包中的其它类才可以直接访问这些缺省成员（与protected的区别是，不同包中的子类不可以访问）</p></li><li><p><strong>Final:</strong> </p><ul><li><p>修饰<strong>类</strong>时：不可被继承；</p></li><li><p>修饰<strong>方法</strong>时，不可被重写，可以被继承；</p></li><li><p>修饰<strong>引用</strong>时，若为基本数据类型，则为常量，不可修改；若为引用数据类型，则地址不可修改，对象本身的属性可以修改</p><p>final int[] {1, 3, 2}; arr[2] = 4; <del>arr = new int[] {12341};</del>（不可修改地址）</p></li></ul></li><li><p><strong>Static:</strong> 可以在没有创建对象的情况下来进行调用（方法/变量）</p><ul><li><p>修饰<strong>方法</strong>时：静态方法，可以在没有创建对象的情况下来进行调用（方法/变量），不依附于任何对象，因此没有this；静态方法<strong>不可以</strong>访问成员的非静态方法/变量；非静态方法可以访问静态方法/变量</p></li><li><p>修饰<strong>变量</strong>时：静态变量，静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响</p></li><li><p>修饰<strong>代码块</strong>时：用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次</p><p>static { </p><p>//代码块（只会在类加载的时候执行一次）</p><p>}</p></li><li><p><strong>注意⚠️</strong>：Java中的static不可以用于修饰局部变量；static不改变成员的访问权限（只受public private protected影响）</p></li></ul></li></ul><h3 id="Chapter-5-（继承与多态）"><a href="#Chapter-5-（继承与多态）" class="headerlink" title="Chapter-5 （继承与多态）"></a>Chapter-5 （继承与多态）</h3><ol><li><p><strong>继承</strong>：Java只支持单继承，即只能有一个父类，但类之间的继承可以具有传递性；子类可以通过继承获得父类中<strong>除访问权限为private</strong>的成员变量和方法</p><ul><li><p>格式：</p><p>class  子类名  extends  父类名{</p><pre><code> 类体</code></pre><p>}</p></li></ul></li><li><p><strong>重写（override）</strong>：在类的继承过程中，如果子类中新增的变量和方法与父类中的变量和方法<strong>同名</strong>，则称为重写（或覆盖）；方法重写不仅要求父类与子类中的方法名称相同，而且参数列表也要相同，只是实现的功能不同</p></li><li><p><strong>super</strong>：</p><ol><li>用来<strong>引用当前对象的父类</strong>，可以使用它访问父类中被覆盖的成员<ul><li>格式：super.method</li></ul></li><li><strong>调用父类中的某一个构造函数</strong>（应该为构造函数中的第一条语句）；若类没有任何构造方法，编译器会自动添加一个无参构造方法，在此方法中只有一条语句super()，若已有有参的构造方法，则不会自动添加<ul><li>格式：super(参数);</li></ul></li></ol></li><li><p><strong>this</strong>：是自身的一个对象，代表对象本身，可以理解为：<strong>指向对象本身的一个指针</strong></p><ol><li><p>普通的<strong>直接引用</strong>，this 相当于是指向当前对象本身</p></li><li><p><strong>形参与成员名字重名，用 this 来区分</strong>：</p><ul><li><p>public int GetAge(int age){</p><p>​        this.age = age;        </p><p>return this.age;             //这里 age 是 GetAge 成员方法的形参，this.age 是 Person 类的成员变量</p><p> }</p></li></ul></li><li><p><strong>引用构造函数</strong>；调用本类中另一种形式的构造函数（应该为构造函数中的第一条语句）</p><ul><li>格式：this(参数);</li></ul></li></ol></li></ol><p><strong>注意⚠️：</strong>this和 super都指的是对象，所以，均<strong>不可以</strong>在 <strong>static</strong> 环境中使用</p><ol start="5"><li><p><strong>类型转换</strong></p><ol><li><p>如果是子类对象转换为父类，可进行显式转换或隐式转换：</p><p>Dad = (father) A</p><p>Child = (child) B    //显式转换</p></li><li><p>如果是父类对象转换成子类，编译器首先要检查这种转换的可行性，如果可行，则必须进行<strong>显式转换</strong></p></li></ol></li><li><p><strong>多态</strong>：多态性就是一个名称可以对应多种不同的实现方法；对重写的方法，Java根据调用该方法的实例的类型来决定选择哪个方法（c++需要添加virtual）</p></li><li><p><strong>抽象类（abstract）</strong>：Java 中抽象类表示的是一种继承关系，一个类只能继承一个抽象类，而一个类却可以实现多个接口</p><ol><li>抽象类不能被实例化，必须被继承；抽象方法只有方法的返回值、名称和参数列表，没有方法体，它必须在子类中具体实现该方法</li><li>抽象类没有自己的主体（没有{}包起来的 业务逻辑），跟接口中的方法有点类似。所以没法直接调用抽象方法</li><li>抽象类可以比作不同的交通工具有不同的结果，自行车靠骑，汽车靠发动机运行；因此抽象类只是提供一个 交通工具类（），具体到自行车还是汽车，需要被子类所继承/重写；抽象方法也是同理。因此，抽象方法不可以是static或private，因为抽象方法没有主体，且需要权限访问重写</li></ol></li><li><p><strong>接口（interface）</strong>：是一个抽象类型，是抽象方法的集合</p><ol><li>接口中的所有方法都是抽象的（可以不写abstract），也没有方法体{}；接口中的所有数据都是静态常量（static,final可以不写）</li><li>一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类</li><li>接口支持多继承（可以有多个父类）</li></ol><ul><li><p>格式：</p><p>[可见度] interface 接口名称 [extends 其他的接口名] { </p><p>​              // 声明变量        // 抽象方法 </p><p>}</p></li></ul></li><li><p><strong>接口实现：</strong>当类实现接口的时候，类要实现接口中所有的方法。否则，类必须声明为抽象的类；类使用implements关键字实现接口。在类声明中，Implements关键字放在class声明后面</p><ul><li>格式：<code>...implements 接口名称[, 其他接口名称, 其他接口名称..., ...] ...</code></li></ul></li><li><p><strong>内部类：</strong></p><ol><li><p>成员内部类：成员内部类是最普通的内部类，它的定义为位于另一个类的内部</p><ul><li><p>员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）;　</p></li><li><p>不过要注意的是，当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：外部类.this.成员变量/方法；</p></li><li><p>在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问（需要先new一个内部类）</p><p>Test outer = new Test();</p><p>Test.inner in = outer.new inner();</p></li></ul></li><li><p>局部内部类：</p><ul><li>局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内</li><li>局部内部类就像是方法里面的一个局部变量一样，是<strong>不能有</strong>public、protected、private以及static修饰符</li></ul></li><li><p>匿名内部类：</p><ul><li><p>可以在定义一个类的同时将它实例化，与局部内部类很相似，区别是它没有类名；如果某个类只需要使用一次，则可以选择采用匿名内部类来简化代码。</p></li><li><p>前提：必须继承一个父类或实现一个接口,然后继承或重写父类或接口中的方法</p></li><li><p>格式：father name = new father(){</p><p>​                public void xxx{</p><p>​                }</p><p>​            };</p></li></ul></li><li><p>静态内部类：静态内部类也是定义在另一个类里面的类，只不过在类的前面多了一个关键字static</p><ul><li>一旦内部类使用static修饰，这个类就为顶级类；除了写在类内部以外，具有外部类的一切特性</li><li>静态内部类可以在内部定义static元素，在构建对象时可以一次性完成（非静态需要先new一个外部类）</li><li><strong>内部接口</strong>自动具有static属性，普通类可以直接实现接口</li></ul></li></ol></li><li><p><strong>Lambda表达式：</strong>用函数表达式代替常规的代码</p><ol><li><p>特性：</p><ul><li><strong>可选类型声明：</strong>不需要声明参数类型，编译器可以统一识别参数值</li><li><strong>可选的参数圆括号：</strong>一个参数无需定义圆括号，但多个参数需要定义圆括号</li><li><strong>可选的大括号：</strong>如果主体包含了一个语句，就不需要使用大括号</li><li><strong>可选的返回关键字：</strong>如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定表达式返回了一个数值</li></ul></li><li><p>语法格式：</p><p>(parameters) -&gt; expression      或      (parameters) -&gt;{ statements; return;}</p></li><li><p>可以用lambda表达式代替匿名内部类或Runnable接口</p></li><li><p>例子：</p><ul><li>```java<br>Comparator c = (Person p1, Person p2) -&gt; p1.getAge().compareTo(p2.getAge());<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- ```java</span><br><span class="line">  features.forEach(n -&gt; System.out.println(n));</span><br></pre></td></tr></table></figure></li></ul></li></ol></li><li><p><strong>泛型:</strong></p><ol><li><p>操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法</p></li><li><p>常见的如<strong>T、E、K、V</strong>等形式的参数常用于表示泛型</p></li><li><p><strong>泛型类：</strong></p><ul><li>格式：（泛型的类型参数只能是类类型，不能是简单类型）</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 类名称 &lt;泛型标识：可以随便写任意标识号，标识指定的泛型的类型&gt;</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> 泛型标识 <span class="comment">/*（成员变量类型）*/</span> <span class="keyword">var</span>; </span><br><span class="line">  .....</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//exp:</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Generic</span>&lt;<span class="title">T</span>&gt;</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> T key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>泛型接口:</strong></p><ul><li><p>格式：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义一个泛型接口</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Generator</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">next</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>泛型方法：</strong></p><ol><li>泛型方法，是在调用方法的时候指明泛型的具体类型</li></ol><ul><li><p>格式：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">genericMethod</span><span class="params">(Class&lt;T&gt; tClass)</span><span class="keyword">throws</span> InstantiationException ,</span></span><br><span class="line"><span class="function">  IllegalAccessException</span>&#123;</span><br><span class="line">        T instance = tClass.newInstance();</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br></pre></td></tr></table></figure></li></ul></li></ol></li><li><p><strong>注解：</strong>注解就是对于代码中某些鲜活个体的贴上去的一张标签</p><ol><li><p><strong>元注解</strong></p><ul><li><p>元注解是可以注解到注解上的注解，或者说元注解是一种基本注解</p></li><li><p>元标签有 @Retention、@Documented、@Target、@Inherited、@Repeatable 5 种</p><ol><li><p><strong>@Retention</strong></p><ul><li><p>它解释说明了这个注解的的存活时间</p></li><li><p>它的取值如下：</p><ol><li><p>RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视。</p></li><li><p>RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中。</p></li><li><p>RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。</p></li></ol></li></ul></li><li><p><strong>@Documented</strong></p><ul><li>它的作用是能够将注解中的元素包含到 Javadoc 中去</li></ul></li><li><p><strong>@Target</strong></p><ol><li>指定了注解运用的地方，当一个注解被 @Target 注解时，这个注解就被限定了运用的场景</li><li>@Target 有下面的取值<ul><li>ElementType.ANNOTATION_TYPE 可以给一个注解进行注解</li><li>ElementType.CONSTRUCTOR 可以给构造方法进行注解</li><li>ElementType.FIELD 可以给属性进行注解</li><li>ElementType.LOCAL_VARIABLE 可以给局部变量进行注解</li><li>ElementType.METHOD 可以给方法进行注解</li><li>ElementType.PACKAGE 可以给一个包进行注解</li><li>ElementType.PARAMETER 可以给一个方法内的参数进行注解</li><li>ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举</li></ul></li></ol></li><li><p><strong>@Inherited</strong></p><ul><li>Inherited 是继承的意思，但是它并不是说注解本身可以继承，而是说如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类没有被任何注解应用的话，那么这个子类就继承了超类的注解</li><li>注解 Test 被 @Inherited 修饰，之后类 A 被 Test 注解，类 B 继承 A,类 B 也将拥有 Test 这个注解</li></ul></li><li><p><strong>@Repeatable</strong></p><ul><li>可重复的意思，标识某注解可以在同一个声明上使用多次</li><li>Persons 是一张总的标签，上面贴满了 Person 这种同类型但内容不一样的标签。把 Persons 给一个 SuperMan 贴上，相当于同时给他贴了程序员、产品经理、画家的标签</li></ul></li></ol></li></ul></li><li><p><strong>注解的属性</strong></p><ol><li><p>注解的属性也叫做成员变量。注解只有成员变量，没有方法。注解的成员变量在注解的定义中以“无形参的方法”形式来声明，其方法名定义了该成员变量的名字，其返回值定义了该成员变量的类型</p></li><li><p>赋值的方式是在注解的括号内以 value=”” 形式，多个属性之前用 ，隔开  <code>@&lt;注解名&gt;(&lt;成员名1&gt;=&lt;成员值1&gt;,&lt;成员名1&gt;=&lt;成员值1&gt;,...)</code></p></li><li><p>需要注意的一种情况是一个注解没有任何属性  public @interface Perform {}</p><p>那么在应用这个注解的时候，括号都可以省略  @Perform</p></li></ol></li><li><p><strong>Java预置的注解</strong></p><ol><li><p><strong>@Deprecated</strong></p><p>这个元素是用来标记过时的元素。编译器在编译阶段遇到这个注解时会发出提醒警告，告诉开发者正在调用一个过时的元素比如过时的方法、过时的类、过时的成员变量</p></li><li><p><strong>@Override</strong></p><p>提示子类要复写父类中被 @Override 修饰的方法</p></li><li><p><strong>@SuppressWarnings</strong></p><p>阻止警告的意思，调用被 @Deprecated 注解的方法后，编译器会警告提醒，而有时候开发者会忽略这种警告，他们可以在调用的地方通过 @SuppressWarnings 达到目的</p></li><li><p><strong>@SafeVarargs</strong></p><p>参数安全类型注解，它的目的是提醒开发者不要用参数做一些不安全的操作,它的存在会阻止编译器产生 unchecked 这样的警告。它是在 Java 1.7 的版本中加入的</p></li><li><p><strong>@FunctionalInterface</strong></p><ul><li><p>函数式接口注解，这个是 Java 1.8 版本引入的新特性。函数式接口 (Functional Interface) 就是一个具有一个方法的普通接口。</p></li><li><p>进行线程开发中常用的 Runnable 就是一个典型的函数式接口可以看到它就被 @FunctionalInterface 注解</p></li></ul></li></ol></li><li><p><strong>自定义注解</strong></p><ul><li>格式：public @interface 注解名 {定义体}</li></ul></li></ol></li></ol><h3 id="Chapter-6（标准类库）"><a href="#Chapter-6（标准类库）" class="headerlink" title="Chapter-6（标准类库）"></a>Chapter-6（标准类库）</h3><ol><li><p>字符串类：</p><ol><li><p>String的构造：</p><ul><li><p>String s = new String(“String test”); </p></li><li><p>String s = “String test”;</p></li><li><p>```java<br>char temp_box[] = {‘a’, ‘b’, ‘c’};   //数组构造<br>String temp3 = new String(temp_box);</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">2. 常用方法：</span><br><span class="line"></span><br><span class="line">   - **.length()**   求String长度</span><br><span class="line">   - **.equals()**   判断两个字符串是否相同</span><br><span class="line">   - **.compareTo()**   长度相同,从第一位开始比较，如果相同返回0，如果不同则马上返回这两个字符的ascii值的差值; 长度不同,直接返回长度差值</span><br><span class="line">   - **.indexOf()**   由前向后查找指定字符串位置，如果超找到了则返回（第一个字母）位置索引，如果找不到返回-1</span><br><span class="line">   - **.substring(int beginIndex,int endIndex)**   获得的子串是从当前字符串的beginIndex处开始截取到endIndex-1结束所得到的字符串</span><br><span class="line">   - **.replaceAll(String old, String new)**   用new字符串替换old字符串</span><br><span class="line">   - **.trim()**   用于删除字符串的头尾空白符</span><br><span class="line"></span><br><span class="line">3. StringBuffer类：</span><br><span class="line"></span><br><span class="line">   - 对字符串进行修改时，需要使用StringBuffer类；StringBuffer类可以多次修改，并且不产生新的未使用对象（因为只对StringBuffer对象本身进行操作）</span><br><span class="line"></span><br><span class="line">4. StringBuilder类：</span><br><span class="line"></span><br><span class="line">   - StringBuilder 类在 Java 5 中被提出，它和 StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的；且相较于StringBuffer，有速度优势</span><br><span class="line"></span><br><span class="line">   - ```java</span><br><span class="line">     //代码事例：</span><br><span class="line">     StringBuilder temp = new StringBuilder(10);  //capacity = 10</span><br><span class="line">     temp.append(&quot;noob..&quot;);</span><br><span class="line">     temp.insert(3,&quot;a&quot;);</span><br></pre></td></tr></table></figure></li><li><p>常用方法：</p><ul><li><strong>.capacity()</strong>   返回当前容量 </li><li><strong>.append(String value)</strong>  添加指定字符串到此序列</li><li><strong>.insert(int index, String value)</strong>    在index处插入字符串value</li><li><strong>.reverse()</strong>   将此字符串用反转形式取代</li><li><strong>.delete(int start, int end)</strong>   删除 [start,end) 处的字符串</li><li><strong>.replace(int start, int end, String value)</strong>   使用给定value中的字符替换此序列的子字符串中[start,end)的字符</li></ul></li></ul></li><li><p>System类：</p><ul><li><strong>.currentTimeMillis( )</strong>   返回自1970年1月1日午夜起到现在的时间，时间单位是毫秒</li><li><strong>.arraycopy(src, src_start_Pos, dest, dest_start_Pos, length)</strong>   可以将一个任意类型的数组快速地从一个地方复制到另一个地方(这比使用Java中编写的循环要快的多);需要注意的是目标数组相对应位置上的元素会被覆盖掉</li></ul></li><li><p>Runtime类：</p><ul><li><p>Runtime r = new Runtime.getRuntime()； </p><p>r.totalMemory();   r.freeMemory();         可以用于获取Java虚拟机内部的内存使用</p></li></ul></li><li><p>Math类：</p><ul><li><strong>.nextInt(int n)</strong>   返回一个[0,n) 的随机整数</li><li><strong>.nextDouble();  .nextLong();  .nextBoolean();</strong>   返回一个随机值</li></ul></li><li><p>Collection集合类：</p><ul><li>主要分为3种：Set、Map和List</li><li>面向接口编程，先定义接口，再定义实现类</li><li>常用方法：<ul><li>.add(); .remove(); .size(); .toarray();</li></ul></li></ul></li><li><p>ArrayList类：</p><ul><li><p>Iterator：</p><p>ArrayList al = new ArrayList();</p><p>Iterator it = al.iterator();</p></li><li><p>Map;HashMap;Set;HashSet;TreeSet类</p></li></ul></li></ol></li></ol><h3 id="Chapter-7（异常处理）"><a href="#Chapter-7（异常处理）" class="headerlink" title="Chapter-7（异常处理）"></a>Chapter-7（异常处理）</h3><p>异常的根类是 <strong>Throwable</strong> ，异常类可以分为<strong>Error</strong>和<strong>Exception</strong></p><ol><li><p><strong>Error</strong></p><p>Error通常是无法处理的异常，比如OutOfMemoryError，一般发生这种异常，JVM会选择终止程序</p></li><li><p><strong>Exception</strong></p><p>Exception是可以处理的异常，比如NullPointerException、IndexOutOfBoundsException；Exception类的异常包括checked exception和unchecked exception（unchecked exception也称运行时异常RuntimeException，当然这里的运行时异常并不是前面所说的运行期间的异常，只是Java中用运行时异常这个术语来表示，Exception类的异常都是在运行期间发生的）</p><ul><li><p><strong>unchecked exception（非检查异常）</strong></p><p>也称运行时异常（RuntimeException），比如常见的NullPointerException、IndexOutOfBoundsException。对于运行时异常，java编译器不要求必须进行异常捕获处理或者抛出声明，由程序员自行决定</p></li><li><p><strong>checked exception（检查异常）</strong></p><p>也称非运行时异常（运行时异常以外的异常就是非运行时异常），java编译器强制程序员必须进行捕获处理，比如常见的IOExeption和SQLException。对于非运行时异常如果不进行捕获或者抛出声明处理，编译都不会通过</p></li></ul></li><li><p><strong>异常的处理</strong></p><ol><li><p><strong>Try…catch…finally</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">     <span class="comment">//try块中放可能发生异常的代码    </span></span><br><span class="line">   <span class="comment">//如果执行完try且不发生异常，则接着去执行finally块和finally后面的代码（如果有的话）</span></span><br><span class="line">   <span class="comment">//如果发生异常，则尝试去匹配catch块</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(SQLException SQLexception)&#123;</span><br><span class="line">     <span class="comment">//每一个catch块用于捕获并处理一个特定的异常，或者这异常类型的子类。Java7中可以将多个异常声明在一个catch中</span></span><br><span class="line">     <span class="comment">//catch后面的括号定义了异常类型和异常参数。如果异常与之匹配且是最先匹配到的，则虚拟机将使用这个catch块来处理异常</span></span><br><span class="line">     <span class="comment">//在catch块中可以使用这个块的异常参数来获取异常的相关信息。异常参数是这个catch块中的局部变量，其它块不能访问</span></span><br><span class="line">     <span class="comment">//如果当前try块中发生的异常在后续的所有catch中都没捕获到，则先去执行finally，然后到这个函数的外部caller中去匹配异常处理器</span></span><br><span class="line">    <span class="comment">//如果try中没有发生异常，则所有的catch块将被忽略</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(Exception exception)&#123;</span><br><span class="line">    <span class="comment">//如果同一个try块下的多个catch异常类型有父子关系，应该将子类异常放在前面，父类异常放在后面</span></span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">      <span class="comment">//finally块通常是可选的   </span></span><br><span class="line">  <span class="comment">//无论异常是否发生，异常是否匹配被处理，finally都会执行</span></span><br><span class="line">   <span class="comment">//一个try至少要有一个catch块，否则， 至少要有1个finally块。但是finally不是用来处理异常的，finally不会捕获异常</span></span><br><span class="line">    <span class="comment">//finally主要做一些清理工作，如流的关闭，数据库连接的关闭等</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>java中，异常处理的任务就是将执行控制流从异常发生的地方转移到能够处理这种异常的地方去。也就是说：当一个函数的某条语句发生异常时，这条语句的后面的语句不会再执行，它失去了焦点。执行流跳转到最近的匹配的异常处理catch代码块去执行，异常被处理完后，执行流会接着在“处理了这个异常的catch代码块”后面接着执行。</p></li><li><p><strong>Throws函数</strong></p><ul><li><p>throws是另一种处理异常的方式，它不同于try…catch…finally，throws仅仅是将函数中可能出现的异常向调用者声明，而自己则不具体处理</p></li><li><p>如果一个方法内部的代码会抛出检查异常（checked exception），而方法自己又没有完全处理掉，则javac保证你必须在方法的签名上使用throws关键字声明这些可能抛出的异常，否则编译不通过</p></li><li><p>采取这种异常处理的原因可能是：方法本身不知道如何处理这样的异常，或者说让调用者处理更好，调用者需要为可能发生的异常负责</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> <span class="keyword">throws</span> ExceptionType1 , ExceptionType2 ,ExceptionTypeN</span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">     <span class="comment">//foo内部可以抛出 ExceptionType1 , ExceptionType2 ,ExceptionTypeN 类的异常，或者他们的子类的异常对象</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>Throws和Throw</strong></p><ol><li><p>throws  是方法可能抛出异常的声明(用在声明方法时，表示该方法可能要抛出异常)  调用者必须做出处理（捕获或继续抛出）</p><ul><li>  public void doA(int a) <strong>throws</strong> Exception1,Exception3{……}</li></ul></li><li><p>throw  是语句抛出一个异常</p><ul><li>throw e;</li></ul></li><li><p>throws可以单独使用，但throw不能， throw要么和try-catch-finally语句配套使用，要么与throws配套使用。但throws可以单独使用，然后再由处理异常的方法捕获</p></li><li><p>throw语句用在方法体内,表示抛出异常,由方法体内的语句处理 </p><p>throws语句用在方法声明后面,表示再抛出异常,由调用这个方法的上一级方法中的语句来处理，必须做出处理(捕获或继续声明)</p></li><li><p>throws主要是声明这个方法会抛出这种类型的异常，使其他地方调用它时知道要捕获这个异常，使得提醒必须做出处理。否则编译是不会通过的<br>throw是具体向外抛异常的动作，所以它是抛出一个异常实例</p></li></ol></li><li><p><strong>Finally块</strong></p><ol><li>finally块不管异常是否发生，只要对应的try执行了，则它一定也执行。只有一种方法让finally块不执行：System.exit()。因此finally块通常用来做资源释放操作：关闭文件，关闭数据库连接等等。</li><li>良好的编程习惯是：在try块中打开资源，在finally块中清理释放这些资源</li><li>finally块没有处理异常的能力。处理异常的只能是catch块</li><li>在同一try…catch…finally块中 ，如果try中抛出异常，且有匹配的catch块，则先执行catch块，再执行finally块。如果没有catch块匹配，则先执行finally，然后去外面的调用者中寻找合适的catch块</li><li>在同一try…catch…finally块中 ，try发生异常，且匹配的catch块中处理异常时也抛出异常，那么后面的finally也会执行：首先执行finally块，然后去外围调用者中寻找合适的catch块</li><li>在 try块中即便有return，break，continue等改变执行流的语句，finally也会执行</li></ol></li></ol><p>⚠️注意：</p><ol><li><p>当子类重写父类的带有 throws声明的函数时，其throws声明的异常必须在父类异常的可控范围内——用于处理父类的throws方法的异常处理器，必须也适用于子类的这个带throws方法 。这是为了支持多态</p></li><li><p>Java程序可以是多线程的。每一个线程都是一个独立的执行流，独立的函数调用栈。如果程序只有一个线程，那么没有被任何代码处理的异常 会导致程序终止。如果是多线程的，那么没有被任何代码处理的异常仅仅会导致异常所在的线程结束</p><p>也就是说，Java中的异常是线程独立的，线程的问题应该由线程自己来解决，而不要委托到外部，也不会直接影响到其它线程的执行</p></li><li><p>finally和return建议</p><ul><li><p>不要在fianlly中使用return</p></li><li><p>不要在finally中抛出异常</p></li><li><p>减轻finally的任务，不要在finally中做一些其它的事情，finally块仅仅用来释放资源是最合适的</p></li><li><p>将尽量将所有的return写在函数的最后面，而不是try … catch … finally中</p></li></ul></li></ol></li></ol><h3 id="Chapter-8（输入输出处理）"><a href="#Chapter-8（输入输出处理）" class="headerlink" title="Chapter-8（输入输出处理）"></a>Chapter-8（输入输出处理）</h3><ol><li><p>Java流</p><p>标准输入输出，文件的操作，网络上的数据流，字符串流，对象流，zip文件流等等，java中将输入输出抽象称为流，就好像水管，将两个容器连接起来。将数据冲外存中读取到内存中的称为输入流，将数据从内存写入外存中的称为输出流</p><p>流是一个很形象的概念，当程序需要读取数据的时候，就会开启一个通向数据源的流，这个数据源可以是文件，内存，或是网络连接。类似的，当程序需要写入数据的时候，就会开启一个通向目的地的流</p><ul><li><p>流按照流向可以分为两种，输入流InputStream和输出流OutputStream</p></li><li><p>按照处理数据单元可以分为两种，字节流（8位通用字节流）和字符流（16位Unicode字符流）</p><ol><li><p><strong>InputStream抽象类</strong> </p><p>InputStream 为字节输入流，它本身为一个抽象类，必须依靠其子类实现各种功能，此抽象类是表示字节输入流的所有类的超类。 继承自InputStream 的流都是向程序中输入数据的，且数据单位为字节（8bit）</p><p><strong>Inputstream类中的常用方法</strong>： </p><ul><li><strong>public abstract int read( )：</strong>读取一个byte的数据，返回值是高位补0的int类型值。若返回值=-1说明没有读取到任何字节读取工作结束</li><li><strong>public int read(byte b[ ])：</strong>读取b.length个字节的数据放到b数组中。返回值是读取的字节数。该方法实际上是调用下一个方法实现的 </li><li><strong>public int read(byte b[ ], int off, int len)：</strong>从输入流中最多读取len个字节的数据，存放到偏移量为off的b数组中</li><li><strong>public int available( )：</strong>返回输入流中可以读取的字节数。注意：若输入阻塞，当前线程将被挂起，如果InputStream对象调用这个方法的话，它只会返回0，这个方法必须由继承InputStream类的子类对象调用才有用</li><li><strong>public long skip(long n)：</strong>忽略输入流中的n个字节，返回值是实际忽略的字节数, 跳过一些字节来读取 </li><li><strong>public int close( ) ：</strong>我们在使用完后，必须对我们打开的流进行关闭</li></ul></li><li><p><strong>OutputStream抽象类</strong></p><p>OutputStream提供了3个write方法来做数据的输出，这个是和InputStream是相对应的</p><ul><li><p><strong>public void write(byte b[ ])：</strong>将参数b中的字节写到输出流。</p></li><li><p><strong>public void write(byte b[ ], int off, int len) ：</strong>将参数b的从偏移量off开始的len个字节写到输出流。</p></li><li><p><strong>public abstract void write(int b) ：</strong>先将int转换为byte类型，把低字节写入到输出流中</p></li><li><p><strong>public void flush( ) :</strong> 将数据缓冲区中数据全部输出，并清空缓冲区</p></li><li><p><strong>public void close( ) :</strong> 关闭输出流并释放与流相关的系统资源</p></li></ul><p><em>流结束的判断：方法read()的返回值为-1时；readLine()的返回值为null时</em></p></li><li><p><strong>文件输入流： FileInputStream类</strong></p><p>FileInputStream可以使用read()方法一次读入一个字节，并以int类型返回，或者是使用read()方法时读入至一个byte数组，byte数组的元素有多少个，就读入多少个字节。在将整个文件读取完成或写入完毕的过程中，这么一个byte数组通常被当作缓冲区，因为这么一个byte数组通常扮演承接数据的中间角色</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">code01</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException</span>&#123;</span><br><span class="line">        File dir = <span class="keyword">new</span> File(<span class="string">&quot;/Users/calvin/IdeaProjects/test/src/iostream_demon&quot;</span>);</span><br><span class="line">        File f1 = <span class="keyword">new</span> File(dir, <span class="string">&quot;code01.java&quot;</span>);</span><br><span class="line">        System.out.println(f1);</span><br><span class="line">        System.out.println(<span class="string">&quot;exist :&quot;</span> + f1.exists());</span><br><span class="line">        System.out.println(<span class="string">&quot;name :&quot;</span> + f1.getName());</span><br><span class="line">        System.out.println(<span class="string">&quot;path :&quot;</span> + f1.getPath());</span><br><span class="line">        System.out.println(<span class="string">&quot;absolute path :&quot;</span> + f1.getAbsolutePath());</span><br><span class="line">        System.out.println(<span class="string">&quot;parent :&quot;</span> + f1.getParent());</span><br><span class="line">        System.out.println(<span class="string">&quot;is a file :&quot;</span> + f1.isFile());</span><br><span class="line">        System.out.println(<span class="string">&quot;is a dictionary :&quot;</span> + f1.isDirectory());</span><br><span class="line">        System.out.println(<span class="string">&quot;length :&quot;</span> + f1.length());</span><br><span class="line">        File temp_file = File.createTempFile(<span class="string">&quot;temp_file01&quot;</span>,<span class="string">&quot;.tmp&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;absolute path :&quot;</span> + temp_file.getAbsolutePath());</span><br><span class="line">        System.out.println(<span class="string">&quot;length :&quot;</span> + temp_file.length());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>文件输出流:FileOutputStream类</strong></p><p>用来处理以文件作为数据输出目的数据流；或者说是从内存区读数据入文件</p><p>FileOutputStream类用来处理以文件作为数据输出目的数据流；一个表示文件名的字符串，也可以是File或FileDescriptor对象</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//创建一个文件流对象有两种方法： </span></span><br><span class="line">　　<span class="comment">//方式1： </span></span><br><span class="line">　　 File   f=<span class="keyword">new</span>  File (“d:/myjava/write.txt <span class="string">&quot;);</span></span><br><span class="line"><span class="string">        FileOutputStream  out= new FileOutputStream (f);</span></span><br><span class="line"><span class="string">　　//方式2： </span></span><br><span class="line"><span class="string">　　FileOutputStream out=new FileOutputStream(“d:/myjava/write.txt &quot;</span>); </span><br><span class="line">　　<span class="comment">//方式3：构造函数将 FileDescriptor()对象作为其参数。 </span></span><br><span class="line">　　FileDescriptor() fd=<span class="keyword">new</span> FileDescriptor(); </span><br><span class="line">　　FileOutputStream f2=<span class="keyword">new</span> FileOutputStream(fd); </span><br><span class="line">　　<span class="comment">//方式4：构造函数将文件名作为其第一参数，将布尔值作为第二参数。 </span></span><br><span class="line">　　FileOutputStream f=<span class="keyword">new</span> FileOutputStream(<span class="string">&quot;d:/abc.txt&quot;</span>,<span class="keyword">true</span>); </span><br><span class="line">　　<span class="comment">//注意： （1）文件中写数据时，若文件已经存在，则覆盖存在的文件；（2）的读/写操作结束时，应调用close方法关闭流</span></span><br></pre></td></tr></table></figure></li><li><p><strong>缓冲输入输出流</strong> <strong>BufferedInputStream/ BufferedOutputStream</strong></p><ol><li><p>计算机访问外部设备非常耗时。访问外存的频率越高，造成CPU闲置的概率就越大。为了减少访问外存的次数，应该在一次对外设的访问中，读写更多的数据。为此，除了程序和流节点间交换数据必需的读写机制外，还应该增加缓冲机制。缓冲流就是每一个数据流分配一个缓冲区，一个缓冲区就是一个临时存储数据的内存。这样可以减少访问硬盘的次数,提高传输效率</p></li><li><p>BufferedInputStream:当向缓冲流写入数据时候，数据先写到缓冲区，待缓冲区写满后，系统一次性将数据发送给输出设备</p></li><li><p>BufferedOutputStream :当从向缓冲流读取数据时候，系统先从缓冲区读出数据，待缓冲区为空时，系统再从输入设备读取数据到缓冲区</p><ul><li><p><strong>将文件读入内存：</strong></p><p>将BufferedInputStream与FileInputStream相接</p><p> FileInputStream in=new FileInputStream( “file1.txt ” );</p><p> BufferedInputStream bin=new BufferedInputStream( in); </p></li><li><p><strong>将内存写入文件：</strong></p><p>将BufferedOutputStream与 FileOutputStream相接</p><p>FileOutputStreamout=new FileOutputStream(“file1.txt”);</p><p>BufferedOutputStream bin=new BufferedInputStream(out);</p></li><li><p><strong>键盘输入流读到内存</strong></p><p>将BufferedReader与标准的数据流相接 </p><p> InputStreamReader sin=new InputStreamReader (System.in) ；</p><p>BufferedReader bin=new       BufferedReader(sin);</p></li></ul></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//缓冲流实现文件复制</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">code02</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> size;</span><br><span class="line">        FileInputStream f = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;/Users/calvin/IdeaProjects/test/src/iostream_demon/code02.java&quot;</span>);</span><br><span class="line">        FileOutputStream fout = <span class="keyword">new</span> FileOutputStream(<span class="string">&quot;copy-of-file.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        BufferedInputStream bis = <span class="keyword">new</span> BufferedInputStream(f);</span><br><span class="line">        BufferedOutputStream bos = <span class="keyword">new</span> BufferedOutputStream(fout);</span><br><span class="line">        System.out.println(<span class="string">&quot;Start Copy Process: &quot;</span>);</span><br><span class="line">        <span class="keyword">int</span> n = f.available();</span><br><span class="line">        <span class="keyword">byte</span> b[] = <span class="keyword">new</span> <span class="keyword">byte</span>[n];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> ((count = bis.read(b, <span class="number">0</span>, n)) != -<span class="number">1</span>)</span><br><span class="line">            bos.write(b, <span class="number">0</span>, n);</span><br><span class="line">        System.out.println(<span class="string">&quot;Copy End&quot;</span>);</span><br><span class="line">        bis.close();</span><br><span class="line">        bos.flush();</span><br><span class="line">        bos.close();</span><br><span class="line">        f.close();</span><br><span class="line">        fout.flush();</span><br><span class="line">        fout.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ul></li></ol><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用Fake-Location实现代跑</title>
      <link href="/2021/06/13/%E5%88%A9%E7%94%A8fake-location%E5%AE%9E%E7%8E%B0%E4%BB%A3%E8%B7%91/"/>
      <url>/2021/06/13/%E5%88%A9%E7%94%A8fake-location%E5%AE%9E%E7%8E%B0%E4%BB%A3%E8%B7%91/</url>
      
        <content type="html"><![CDATA[<h1 id="利用Fake-Location实现代跑"><a href="#利用Fake-Location实现代跑" class="headerlink" title="利用Fake Location实现代跑"></a>利用Fake Location实现代跑</h1><p>大学每学期需要乐跑30次（30 * 3km），而我又是一条懒狗，所以就想到用虚拟定位来代跑。如果碰巧你和我一样也是一条懒狗，那不妨也试试。</p><blockquote><p>目前已知Keep和步道乐跑可以正常用，其他跑步软件没试过，应该没有太大问题。</p></blockquote><h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>需要用到的设备：</p><ul><li>一部安卓手机</li><li>🧠</li></ul><h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><h3 id="1-获取root权限"><a href="#1-获取root权限" class="headerlink" title="1.获取root权限"></a>1.获取root权限</h3><blockquote><p>如果你的手机已经root，可以跳到下一步。</p></blockquote><p>由于目前大多数手机root非常麻烦，所以我们选择使用虚拟机来实现这一步骤。</p><ul><li><p>Step1. 下载 VMOS Pro（应用商店里应该都有，没有就去百度上下载）</p></li><li><p>Step2. 进入VMOS Pro，选择一个自带root的ROM，如安卓7.1精简版。带Root的ROM一般需要会员，你可以选择每天看广告用积分白嫖，或是充值会员。</p></li><li><p>Step3.进入ROM，点击Setting，勾选超级用户选项<img src="/pic2.jpg" class="lazyload" data-srcset="/pic2.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p></li><li><p>Step4. 进入设置（不是Setting），选择关于手机，点击版本号5次，当设备显示“开发者模式已启用”，返回虚拟机桌面</p></li></ul><h3 id="2-下载Fake-Location"><a href="#2-下载Fake-Location" class="headerlink" title="2.下载Fake Location"></a>2.下载Fake Location</h3><p>选择桌面底部黄色图标，导入“步道乐跑”、“Fake Location”和QQ</p><p>Fake Location的下载链接百度上可以找到。</p><h3 id="3-配置Fake-Location"><a href="#3-配置Fake-Location" class="headerlink" title="3.配置Fake Location"></a>3.配置Fake Location</h3><ul><li><p>进入Fake Location</p><p><img src="/pic3.jpg" class="lazyload" data-srcset="/pic3.jpg" srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></p></li><li><p>将“步道乐跑”加入反检测和Root隐藏中，并开启反检测和Root隐藏。反检测和Root隐藏需要会员，每月好像是10块钱。</p></li><li><p>点击路线模拟，点击➕绘制跑步路线，并设置步频和速度（过快或过慢成绩会无效）</p></li><li><p>启动模拟，并进入步道乐跑，开始跑步，跑完记得关掉。</p></li></ul><h2 id="PS"><a href="#PS" class="headerlink" title="PS"></a>PS</h2><p>以后每次使用只需按照【3】的步骤，如果VMOS Pro开通会员，每天大约需要15分钟即可完成跑步。不开通会员，看广告白嫖大约需要20分钟。当然，跑步的时候你可以做自己的事情，也就是说真正花费的时间只是【3】中配置的时间，大约需要5分钟。</p><blockquote><p>当然，在大学中适当的体育锻炼还是有必要的，所以请合理使用代跑。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代跑 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode&amp;洛谷刷题笔记</title>
      <link href="/2021/06/08/leetcode-%E6%B4%9B%E8%B0%B7%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/"/>
      <url>/2021/06/08/leetcode-%E6%B4%9B%E8%B0%B7%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-时间复杂度"><a href="#1-时间复杂度" class="headerlink" title="1.时间复杂度"></a>1.时间复杂度</h2><p><strong>常数阶O(1)&lt;对数阶O(log2n)&lt;线性阶O(n),&lt;线性对数阶O(nlog2n)&lt;平方阶O(n^2)&lt;方阶O(n3)&lt;k次方阶O(n^k)&lt;指数阶O(2^n)&lt;O(n!)&lt;O(n^n)</strong></p><h2 id="2-快读"><a href="#2-快读" class="headerlink" title="2.快读"></a>2.快读</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">()</span></span>&#123;</span><br><span class="line">   <span class="keyword">register</span> <span class="keyword">int</span> s=<span class="number">0</span>,w=<span class="number">1</span>;</span><br><span class="line">   <span class="keyword">register</span> <span class="keyword">char</span> ch=<span class="built_in">getchar</span>();</span><br><span class="line">   <span class="keyword">while</span>(ch&lt;<span class="string">&#x27;0&#x27;</span>||ch&gt;<span class="string">&#x27;9&#x27;</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(ch==<span class="string">&#x27;-&#x27;</span>)&#123;</span><br><span class="line">            w=<span class="number">-1</span>;</span><br><span class="line">            ch=<span class="built_in">getchar</span>();   </span><br><span class="line">        &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">while</span>(ch&gt;=<span class="string">&#x27;0&#x27;</span>&amp;&amp;ch&lt;=<span class="string">&#x27;9&#x27;</span>) &#123;</span><br><span class="line">        s=s*<span class="number">10</span>+ch-<span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">        ch=<span class="built_in">getchar</span>();</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> s*w;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-贪心算法"><a href="#3-贪心算法" class="headerlink" title="3.贪心算法"></a>3.贪心算法</h2><p>所谓贪心算法是指，在对问题求解时，总是<strong>做出在当前看来是最好的选择</strong>。也就是说，不从整体最优上加以考虑，它所做出的仅仅是在某种意义上的<strong>局部最优解</strong>。<br>贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性（即某个状态以后的过程不会影响以前的状态，只与当前状态有关。）<br><strong>所以，对所采用的贪心策略一定要仔细分析其是否满足无后效性。</strong></p><p>例：背包问题</p><h2 id="4-快排"><a href="#4-快排" class="headerlink" title="4.快排"></a>4.快排</h2><p>快速排序是C.R.A.Hoare于1962年提出的一种划分交换排序。它采用了一种分治的策略，通常称其为分治法(Divide-and-ConquerMethod)。</p><p>该方法的基本思想是：</p><ul><li><p>1．先从数列中取出一个数作为基准数。</p></li><li><p>2．分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。</p></li><li><p>3．再对左右区间重复第二步，直到各区间只有一个数。 </p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//快速排序 传统</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quick_sort</span><span class="params">(<span class="keyword">int</span> s[], <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &lt; r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//Swap(s[l], s[(l + r) / 2]); //将中间的这个数和第一个数交换 参见注1</span></span><br><span class="line">        <span class="keyword">int</span> i = l, j = r, x = s[l];</span><br><span class="line">        <span class="keyword">while</span> (i &lt; j)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">while</span>(i &lt; j &amp;&amp; s[j] &gt;= x) <span class="comment">// 从右向左找第一个小于x的数</span></span><br><span class="line">                j--;  </span><br><span class="line">            <span class="keyword">if</span>(i &lt; j) </span><br><span class="line">                s[i++] = s[j];</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span>(i &lt; j &amp;&amp; s[i] &lt; x) <span class="comment">// 从左向右找第一个大于等于x的数</span></span><br><span class="line">                i++;  </span><br><span class="line">            <span class="keyword">if</span>(i &lt; j) </span><br><span class="line">                s[j--] = s[i];</span><br><span class="line">        &#125;</span><br><span class="line">        s[i] = x;</span><br><span class="line">        <span class="built_in">quick_sort</span>(s, l, i - <span class="number">1</span>); <span class="comment">// 递归调用 </span></span><br><span class="line">        <span class="built_in">quick_sort</span>(s, i + <span class="number">1</span>, r);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//洛谷</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qsort</span><span class="params">(<span class="keyword">int</span> l,<span class="keyword">int</span> r)</span><span class="comment">//应用二分思想</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid=a[(l+r)/<span class="number">2</span>];<span class="comment">//中间数</span></span><br><span class="line">    <span class="keyword">int</span> i=l,j=r;</span><br><span class="line">    <span class="keyword">do</span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(a[i]&lt;mid) i++;<span class="comment">//查找左半部分比中间数大的数</span></span><br><span class="line">        <span class="keyword">while</span>(a[j]&gt;mid) j--;<span class="comment">//查找右半部分比中间数小的数</span></span><br><span class="line">        <span class="keyword">if</span>(i&lt;=j)<span class="comment">//如果有一组不满足排序条件（左小右大）的数</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">swap</span>(a[i],a[j]);<span class="comment">//交换</span></span><br><span class="line">            i++;</span><br><span class="line">            j--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">while</span>(i&lt;=j);<span class="comment">//这里注意要有=</span></span><br><span class="line">    <span class="keyword">if</span>(l&lt;j) <span class="built_in">qsort</span>(l,j);<span class="comment">//递归搜索左半部分</span></span><br><span class="line">    <span class="keyword">if</span>(i&lt;r) <span class="built_in">qsort</span>(i,r);<span class="comment">//递归搜索右半部分</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong><code>nth_element</code></strong></p><p>这个函数主要用来将数组元素中第k小的整数排出来并在数组中就位，随时调用，可谓十分实用。</p><p>函数语句：nth_element(数组名,数组名+第k小元素,数组名+元素个数)</p><h2 id="5-RMQ算法"><a href="#5-RMQ算法" class="headerlink" title="5.RMQ算法"></a>5.RMQ算法</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">dp[i][j]=<span class="built_in">min</span>(dp[i][j<span class="number">-1</span>],dp[i+(<span class="number">1</span>&lt;&lt;j<span class="number">-1</span>)][j<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><p>我们设二维数组<code>dp[i][j]</code>表示从第i位开始连续 个数中的最小值。例如<code>dp[2][1]</code>就表示从第二位数开始连续两个数的最小值（也就是从第二位数到第三位数的最小值），即2，6中的最小值，所以<code>dp[2][1] = 2</code>;</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rmq_init</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)</span><br><span class="line">        dp[i][<span class="number">0</span>]=arr[i];<span class="comment">//初始化</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;(<span class="number">1</span>&lt;&lt;j)&lt;=N;j++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i+(<span class="number">1</span>&lt;&lt;j)<span class="number">-1</span>&lt;=N;i++)</span><br><span class="line">            dp[i][j]=<span class="built_in">min</span>(dp[i][j<span class="number">-1</span>],dp[i+(<span class="number">1</span>&lt;&lt;j<span class="number">-1</span>)][j<span class="number">-1</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询部分：</p><p>预处理出整个 <code>dp</code> 数组以后，查询操作很简单，令 <code>k</code> 为满足 2^k&lt;=𝑅−𝐿+12k&lt;=R−L+1 的最大整数，则以 <code>L</code> 开头、以 <code>R</code> 结尾的两个长度为 2^𝑘 的区间合起来即覆盖了查询区间 <code>[L,R]</code> 。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">RMQ</span><span class="params">(<span class="keyword">int</span> L,<span class="keyword">int</span> R)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>((<span class="number">1</span>&lt;&lt;(k+<span class="number">1</span>))&lt;=R-L+<span class="number">1</span>) k++;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">min</span>(dp[L][k],dp[R-(<span class="number">1</span>&lt;&lt;k)+<span class="number">1</span>][k]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-卡特兰数"><a href="#6-卡特兰数" class="headerlink" title="6.卡特兰数"></a>6.卡特兰数</h2><p>递推式1：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">f[n]=f[<span class="number">0</span>]∗f[n−<span class="number">1</span>]+f[<span class="number">1</span>]∗f[n−<span class="number">2</span>]+...+f[n−<span class="number">1</span>]∗f[<span class="number">0</span>](n≥<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>递推式2:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">h[n]=h[n−<span class="number">1</span>]∗(<span class="number">4</span>∗n−<span class="number">2</span>)/(n+<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>递推式3:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">h[n]=C[<span class="number">2</span>n,n]/(n+<span class="number">1</span>)(n=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,...),C是组合数PS: C[m,n]=C[m−<span class="number">1</span>,n−<span class="number">1</span>]+C[m−<span class="number">1</span>,n]且规定： C[n,<span class="number">0</span>]=<span class="number">1</span> C[n,n]=<span class="number">1</span> C[<span class="number">0</span>,<span class="number">0</span>]=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>递推式4:</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">h[n]=C[<span class="number">2</span>n,n]−C[<span class="number">2</span>n,n−<span class="number">1</span>](n=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,...)</span><br></pre></td></tr></table></figure><h2 id="7-DP问题"><a href="#7-DP问题" class="headerlink" title="7.DP问题"></a>7.DP问题</h2><p>建表 得出状态转移方程</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//背包问题</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;    </span><br><span class="line">  <span class="keyword">int</span> n,m;    </span><br><span class="line">  <span class="keyword">int</span> price[<span class="number">110</span>]=&#123;&#125;;    </span><br><span class="line">  <span class="keyword">int</span> a[<span class="number">110</span>][<span class="number">1100</span>]=&#123;&#125;;    </span><br><span class="line">  cin&gt;&gt;n&gt;&gt;m;    </span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++) cin&gt;&gt;price[i];    </span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;        </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=m;j++)&#123;            </span><br><span class="line">      <span class="keyword">if</span> ( j == price[i]) a[i][j] = a[i<span class="number">-1</span>][j] + <span class="number">1</span>;            </span><br><span class="line">      <span class="keyword">if</span> ( j &lt; price[i]) a[i][j] = a[i<span class="number">-1</span>][j];            </span><br><span class="line">      <span class="keyword">if</span> ( j &gt; price[i]) a[i][j] = a[i<span class="number">-1</span>][j] + a[i<span class="number">-1</span>][j-price[i]];          &#125;    </span><br><span class="line">  &#125;    </span><br><span class="line">  cout&lt;&lt;a[n][m]&lt;&lt;endl;    </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-sort排序"><a href="#8-sort排序" class="headerlink" title="8.sort排序"></a>8.sort排序</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N =<span class="number">400</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stu</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> c,m,e;</span><br><span class="line">    <span class="keyword">int</span> sum;</span><br><span class="line">    <span class="keyword">int</span> id;</span><br><span class="line">&#125;arr[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp</span><span class="params">( stu a,stu b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (a.sum !=b.sum) <span class="keyword">return</span> a.sum &gt; b.sum;</span><br><span class="line">    <span class="keyword">if</span> (a.c != b.c) <span class="keyword">return</span> a.c &gt; b.c;</span><br><span class="line">    <span class="keyword">return</span> a.id &lt; b.id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    cin&gt;&gt;n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        <span class="keyword">int</span> a , b, c;</span><br><span class="line">        cin&gt;&gt;a&gt;&gt;b&gt;&gt;c;</span><br><span class="line">        arr[i]=&#123;a,b,c,a+b+c,i&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">sort</span>(arr+<span class="number">1</span>,arr+<span class="number">1</span>+n,cmp);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">5</span>;i++)&#123;</span><br><span class="line">        cout &lt;&lt; arr[i].id &lt;&lt;<span class="string">&quot; &quot;</span>&lt;&lt; arr[i].sum &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>sort(begin,end,(###))</code>###不填默认升序 </p><h2 id="9-二分查找"><a href="#9-二分查找" class="headerlink" title="9.二分查找"></a>9.二分查找</h2><p>1.STL自带二分函数</p><p>函数的用法：<code>lower_bound(a.begin(),a.end(),x)</code> 返回第一个大于等于 x<em>x</em> 的数的地址。而由于是地址，在最后要 −<em>a</em>（也就是减去地址）。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">int</span> n=<span class="built_in">read</span>(),m=<span class="built_in">read</span>();<span class="comment">//读入</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++) a[i]=<span class="built_in">read</span>();</span><br><span class="line"><span class="keyword">while</span>(m--)&#123;</span><br><span class="line"><span class="keyword">int</span> x=<span class="built_in">read</span>();</span><br><span class="line"><span class="keyword">int</span> ans=<span class="built_in">lower_bound</span>(a+<span class="number">1</span>,a+n+<span class="number">1</span>,x)-a;<span class="comment">//二分搜，注意-a</span></span><br><span class="line"><span class="keyword">if</span>(x!=a[ans]) <span class="built_in">printf</span>(<span class="string">&quot;-1 &quot;</span>);<span class="comment">//没有，输出-1</span></span><br><span class="line"><span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,ans);<span class="comment">//有，输出ans</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;<span class="comment">//华丽结束</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="10-DFS深度搜索"><a href="#10-DFS深度搜索" class="headerlink" title="10.DFS深度搜索"></a>10.DFS深度搜索</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//一般框架</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DFS</span><span class="params">(type n)</span></span>&#123;                       <span class="comment">//可以描述阶段的状态</span></span><br><span class="line">  <span class="keyword">if</span>(符合条件) &#123;</span><br><span class="line">    cout&lt;&lt;答案;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;<span class="comment">//出口</span></span><br><span class="line">  <span class="keyword">if</span>(可以剪枝) <span class="keyword">return</span>;                <span class="comment">//剪枝for(i:1~p)&#123;                         //选择该阶段的所有决策选择可行决策;                   //剪枝的一种 标记已访问该点;DFS(n+1);                       //进入下一阶段(还原访问现场;)&#125;&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//连通体判断 - DFS</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">char</span> arr[<span class="number">105</span>][<span class="number">105</span>];  </span><br><span class="line"><span class="keyword">int</span> fxx[<span class="number">9</span>]=&#123;<span class="number">0</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>&#125;;<span class="comment">//x方向</span></span><br><span class="line"><span class="keyword">int</span> fxy[<span class="number">9</span>]=&#123;<span class="number">0</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">1</span>&#125;;<span class="comment">//y方向</span></span><br><span class="line"><span class="keyword">int</span> n,m,ans = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> r,c;</span><br><span class="line">    arr[x][y] = <span class="string">&#x27;.&#x27;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">8</span>;i++)&#123;</span><br><span class="line">        r = x + fxx[i];</span><br><span class="line">        c = y + fxy[i];</span><br><span class="line">        <span class="keyword">if</span> (r&lt;<span class="number">1</span>||r&gt;n||c&lt;<span class="number">1</span>||c&gt;m||arr[r][c] == <span class="string">&#x27;.&#x27;</span>) <span class="keyword">continue</span>;</span><br><span class="line">        arr[r][c] = <span class="string">&#x27;.&#x27;</span>;</span><br><span class="line">        <span class="built_in">dfs</span>(r,c);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>;j &lt;= m;j++)&#123;</span><br><span class="line">            cin&gt;&gt;arr[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>;j &lt;= m;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (arr[i][j] == <span class="string">&#x27;W&#x27;</span>)&#123;</span><br><span class="line">                ans++;</span><br><span class="line">                <span class="built_in">dfs</span>(i,j);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    cout&lt;&lt;ans&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//迷宫</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">int</span> p,q,min = <span class="number">9999999</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">100</span>][<span class="number">100</span>];</span><br><span class="line"><span class="keyword">int</span> v[<span class="number">100</span>][<span class="number">100</span>];</span><br><span class="line"><span class="keyword">int</span> dx[<span class="number">4</span>]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> dy[<span class="number">4</span>]=&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>,<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y,<span class="keyword">int</span> step)</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (x==p &amp;&amp; y==q)&#123;</span><br><span class="line">    <span class="keyword">if</span> (step&lt;min)&#123;</span><br><span class="line">      min = step;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;=<span class="number">3</span>;k++)&#123;</span><br><span class="line">  <span class="keyword">int</span> tx,ty;</span><br><span class="line">    tx = x + dx[k];</span><br><span class="line">    ty = y + dy[k];</span><br><span class="line">    <span class="keyword">if</span> (a[tx][ty] == <span class="number">1</span> &amp;&amp; v[tx][ty] == <span class="number">0</span>)&#123;</span><br><span class="line">      v[tx][ty] = <span class="number">1</span>;</span><br><span class="line">      <span class="built_in">dfs</span>(tx,ty,step+<span class="number">1</span>);</span><br><span class="line">      v[tx][ty] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> startx,starty;</span><br><span class="line">  <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;m,&amp;n);</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=m;i++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=n;j+=)&#123;</span><br><span class="line">      <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;a[i][j]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d%d&quot;</span>,&amp;startx,&amp;starty,&amp;p,&amp;q);</span><br><span class="line">  v[startx][starty] = <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">dfs</span>(startx,starty,<span class="number">0</span>);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,min);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="11-双指针-amp-amp-滑动窗口"><a href="#11-双指针-amp-amp-滑动窗口" class="headerlink" title="11.双指针&amp;&amp;滑动窗口"></a>11.双指针&amp;&amp;滑动窗口</h2><p>​    基本思想就是将串划分子段,如果出现重复，则滑动窗口，变更start的位置，统计新的子串的长度，同时不断更新结果值</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> map[<span class="number">128</span>] = &#123;<span class="number">0</span>&#125;, len = <span class="number">0</span>, start = <span class="number">0</span>;  <span class="comment">//map统计字符在当前子串出现次数,字符的ascii码值小于128</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.<span class="built_in">size</span>(); ++i)    </span><br><span class="line">        &#123;</span><br><span class="line">            ++map[s[i]];</span><br><span class="line">            <span class="keyword">while</span>(map[s[i]] == <span class="number">2</span>)   <span class="comment">//出现重复</span></span><br><span class="line">                --map[s[start++]];  <span class="comment">//不断滑动右移的同时恢复map中的状态，当map[s[i]]=1时，确定新的start</span></span><br><span class="line">            len = <span class="built_in">max</span>(len, i - start + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> len;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="12-Moore投票法"><a href="#12-Moore投票法" class="headerlink" title="12.Moore投票法"></a>12.Moore投票法</h2><p>摩尔投票法，解决的问题是如何在任意多的候选人中，选出票数超过一半的那个人。注意，是超出一半票数的那个人。</p><p>假设投票是这样的，[A, C, A, A, B]，ABC 是指三个候选人。</p><p>第一张票与第二张票进行对坑，如果票不同则互相抵消掉；</p><p>接着第三票与第四票进行对坑，如果票相同，则增加这个候选人的可抵消票数；</p><p>这个候选人拿着可抵消票数与第五张票对坑，如果票不同，则互相抵消掉，即候选人的可抵消票数 -1。</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">majorityElement</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> first_Candidate = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> second_Candidate = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> num1 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> num2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (nums[i] == first_Candidate) num1 ++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (nums[i] == second_Candidate) num2 ++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (num1 == <span class="number">0</span>) &#123;</span><br><span class="line">                first_Candidate = nums[i];</span><br><span class="line">                num1 ++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (num2 == <span class="number">0</span>) &#123;</span><br><span class="line">                second_Candidate = nums[i];</span><br><span class="line">                num2 ++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                num1 --;</span><br><span class="line">                num2 --;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        num1 = <span class="number">0</span>;</span><br><span class="line">        num2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (nums[i] == first_Candidate) num1 ++;</span><br><span class="line">            <span class="keyword">if</span> (nums[i] == second_Candidate) num2 ++;</span><br><span class="line">        &#125;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; result;</span><br><span class="line">        <span class="keyword">if</span> (num1 &gt; nums.<span class="built_in">size</span>() / <span class="number">3</span>) result.<span class="built_in">push_back</span>(first_Candidate);</span><br><span class="line">      <span class="keyword">if</span> (num2 &gt; nums.<span class="built_in">size</span>() / <span class="number">3</span> &amp;&amp; first_Candidate != second_Candidate) result.<span class="built_in">push_back</span>(second_Candidate);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="13-BFS"><a href="#13-BFS" class="headerlink" title="13.BFS"></a>13.BFS</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//迷宫问题</span></span><br><span class="line"><span class="meta">#includebits/stdc++.h</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">100</span>][<span class="number">100</span>];<span class="comment">//a【i】【j】=1表示是空地可以走，为0表示不是空地</span></span><br><span class="line"><span class="keyword">int</span> v[<span class="number">100</span>][<span class="number">100</span>];<span class="comment">//v【i】【j】=1表示已经被访问了，为0表示未被访问</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span>&#123;</span></span><br><span class="line"><span class="keyword">int</span> x;</span><br><span class="line"><span class="keyword">int</span> y;</span><br><span class="line"><span class="keyword">int</span> step;</span><br><span class="line">&#125;;</span><br><span class="line">queue&lt;point&gt; r;<span class="comment">//request queue</span></span><br><span class="line"><span class="keyword">int</span> dx[<span class="number">4</span>]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>&#125;; <span class="comment">//left;down;right;up</span></span><br><span class="line"><span class="keyword">int</span> dy[<span class="number">4</span>]=&#123;<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>,<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">//input</span></span><br><span class="line"><span class="keyword">int</span> n,m,startx,starty,p,q;</span><br><span class="line"><span class="built_in">scanf</span>(%d%d,&amp;n,&amp;m);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i=n;i++)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j=m;j++)&#123;</span><br><span class="line"><span class="built_in">scanf</span>(%d,&amp;a[i][j]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">scanf</span>(%d%d%d%d,&amp;startx,&amp;starty,&amp;p,&amp;q);</span><br><span class="line"></span><br><span class="line"><span class="comment">//BFS</span></span><br><span class="line">point start;</span><br><span class="line"><span class="comment">//初始化开始 </span></span><br><span class="line">start.x = startx;</span><br><span class="line">start.y = starty;</span><br><span class="line">start.step = <span class="number">0</span>;</span><br><span class="line"><span class="comment">//初始化结束</span></span><br><span class="line">r.<span class="built_in">push</span>(start);<span class="comment">//将起点入队 </span></span><br><span class="line">v[startx][starty] = <span class="number">1</span> ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(!r.<span class="built_in">empty</span>())&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(x==p &amp;&amp; y==q)&#123;<span class="comment">// arrive destinationa </span></span><br><span class="line">flag = <span class="number">1</span>;</span><br><span class="line">coutr.<span class="built_in">front</span>().step;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> x = r.<span class="built_in">front</span>().x;</span><br><span class="line"><span class="keyword">int</span> y = r.<span class="built_in">front</span>().y;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span> ; k &lt; <span class="number">3</span> ; k++)&#123;</span><br><span class="line"><span class="keyword">int</span> tx,ty;</span><br><span class="line">tx = x + dx[k];</span><br><span class="line">ty = y + dy[k];</span><br><span class="line"><span class="keyword">if</span> (a[tx][ty]==<span class="number">1</span> &amp;&amp; v[tx][ty]==<span class="number">0</span>)&#123;<span class="comment">//如果是空地 并且 未被访问过 </span></span><br><span class="line"><span class="comment">//入队</span></span><br><span class="line">point temp;<span class="comment">//把拓展的点放到temp里</span></span><br><span class="line">temp.x = tx;</span><br><span class="line">temp.y = ty;</span><br><span class="line">temp.step = r.<span class="built_in">front</span>().step + <span class="number">1</span> ;</span><br><span class="line">r.<span class="built_in">push</span>(temp);</span><br><span class="line">v[tx][ty] = <span class="number">1</span>; <span class="comment">//设置为已访问 </span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">r.<span class="built_in">pop</span>();<span class="comment">//拓展完了需要将队首元素出队</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(flag==<span class="number">0</span>)<span class="comment">//没找到 </span></span><br><span class="line">cout&lt;&lt;no answer&lt;&lt;endl; </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//马的遍历</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">point</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">    <span class="keyword">int</span> y;</span><br><span class="line">    <span class="keyword">int</span> step;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">queue&lt;point&gt; r;</span><br><span class="line"><span class="keyword">int</span> dx[<span class="number">8</span>] = &#123;<span class="number">-1</span>,<span class="number">-2</span>,<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> dy[<span class="number">8</span>] = &#123;<span class="number">-2</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">-1</span>,<span class="number">-2</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a[<span class="number">500</span>][<span class="number">500</span>];</span><br><span class="line"><span class="keyword">int</span> check[<span class="number">500</span>][<span class="number">500</span>];</span><br><span class="line"><span class="comment">//main program</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n,m;  <span class="comment">// width and length</span></span><br><span class="line">    <span class="keyword">int</span> fx,fy;</span><br><span class="line">    <span class="keyword">int</span> startx,starty;</span><br><span class="line">    cin&gt;&gt;n&gt;&gt;m&gt;&gt;fx&gt;&gt;fy;</span><br><span class="line">    startx = fx - <span class="number">1</span>,starty = fy - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> a[n][m];</span><br><span class="line">    <span class="built_in">memset</span>(a,<span class="number">-1</span>,<span class="built_in"><span class="keyword">sizeof</span></span>(a));</span><br><span class="line">    <span class="built_in">memset</span>(check,<span class="number">0</span>,<span class="built_in"><span class="keyword">sizeof</span></span>(check));</span><br><span class="line">    point start;</span><br><span class="line">    start.x = startx, start.y = starty,start.step = <span class="number">0</span>;</span><br><span class="line">    r.<span class="built_in">push</span>(start);</span><br><span class="line">    a[startx][starty] = <span class="number">0</span>;</span><br><span class="line">    check[startx][starty] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(!r.<span class="built_in">empty</span>())&#123;</span><br><span class="line">        <span class="keyword">int</span> next_x = r.<span class="built_in">front</span>().x;</span><br><span class="line">        <span class="keyword">int</span> next_y = r.<span class="built_in">front</span>().y;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>;k&lt;<span class="number">8</span>;k++)&#123;</span><br><span class="line">            <span class="keyword">int</span> tx,ty;</span><br><span class="line">            tx = next_x + dx[k];</span><br><span class="line">            ty = next_y + dy[k];</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (tx&lt;<span class="number">0</span>||tx&gt;n<span class="number">-1</span>||ty&lt;<span class="number">0</span>||ty&gt;m<span class="number">-1</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (check[tx][ty] == <span class="number">1</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                point temp;</span><br><span class="line">                temp.x = tx;</span><br><span class="line">                temp.y = ty;</span><br><span class="line">                temp.step = r.<span class="built_in">front</span>().step + <span class="number">1</span>;</span><br><span class="line">                r.<span class="built_in">push</span>(temp);</span><br><span class="line">                a[tx][ty] = temp.step;</span><br><span class="line">                check[tx][ty] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        r.<span class="built_in">pop</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;m;j++)&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%-5d&quot;</span>,a[i][j]); </span><br><span class="line">        &#125;</span><br><span class="line">        cout&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="14-优先队列"><a href="#14-优先队列" class="headerlink" title="14.优先队列"></a>14.优先队列</h2><p>他和<code>queue</code>不同的就在于我们可以自定义其中数据的优先级, 让优先级高的排在队列前面,优先出队</p><p>优先队列具有队列的所有特性，包括基本操作，只是在这基础上添加了内部的一个排序，它本质是一个堆实现的</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//升序队列</span></span><br><span class="line">priority_queue &lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,greater&lt;<span class="keyword">int</span>&gt; &gt; q;</span><br><span class="line"><span class="comment">//降序队列</span></span><br><span class="line">priority_queue &lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,less&lt;<span class="keyword">int</span>&gt; &gt;q;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;functional&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;queue&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;vector&gt;</span> </span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std; </span><br><span class="line"><span class="comment">//定义结构，使用运算符重载,自定义优先级1 </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cmp1</span>&#123;</span> </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">operator</span> <span class="params">()</span><span class="params">(<span class="keyword">int</span> &amp;a,<span class="keyword">int</span> &amp;b)</span></span>&#123; </span><br><span class="line">        <span class="keyword">return</span> a&gt;b;<span class="comment">//最小值优先 </span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;; </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cmp2</span>&#123;</span> </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">operator</span> <span class="params">()</span><span class="params">(<span class="keyword">int</span> &amp;a,<span class="keyword">int</span> &amp;b)</span></span>&#123; </span><br><span class="line">        <span class="keyword">return</span> a&lt;b;<span class="comment">//最大值优先 </span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;; </span><br><span class="line"><span class="comment">//定义结构，使用运算符重载,自定义优先级2 </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">number1</span>&#123;</span> </span><br><span class="line">    <span class="keyword">int</span> x; </span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (<span class="keyword">const</span> number1 &amp;a) <span class="keyword">const</span> &#123; </span><br><span class="line">        <span class="keyword">return</span> x&gt;a.x;<span class="comment">//最小值优先 </span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;; </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">number2</span>&#123;</span> </span><br><span class="line">    <span class="keyword">int</span> x; </span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (<span class="keyword">const</span> number2 &amp;a) <span class="keyword">const</span> &#123; </span><br><span class="line">        <span class="keyword">return</span> x&lt;a.x;<span class="comment">//最大值优先 </span></span><br><span class="line">    &#125; </span><br><span class="line">&#125;; </span><br><span class="line"><span class="keyword">int</span> a[]=&#123;<span class="number">14</span>,<span class="number">10</span>,<span class="number">56</span>,<span class="number">7</span>,<span class="number">83</span>,<span class="number">22</span>,<span class="number">36</span>,<span class="number">91</span>,<span class="number">3</span>,<span class="number">47</span>,<span class="number">72</span>,<span class="number">0</span>&#125;; </span><br><span class="line">number1 num1[]=&#123;<span class="number">14</span>,<span class="number">10</span>,<span class="number">56</span>,<span class="number">7</span>,<span class="number">83</span>,<span class="number">22</span>,<span class="number">36</span>,<span class="number">91</span>,<span class="number">3</span>,<span class="number">47</span>,<span class="number">72</span>,<span class="number">0</span>&#125;; </span><br><span class="line">number2 num2[]=&#123;<span class="number">14</span>,<span class="number">10</span>,<span class="number">56</span>,<span class="number">7</span>,<span class="number">83</span>,<span class="number">22</span>,<span class="number">36</span>,<span class="number">91</span>,<span class="number">3</span>,<span class="number">47</span>,<span class="number">72</span>,<span class="number">0</span>&#125;; </span><br><span class="line">   </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;   priority_queue&lt;<span class="keyword">int</span>&gt;que;<span class="comment">//采用默认优先级构造队列 </span></span><br><span class="line">   </span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,cmp1&gt;que1;<span class="comment">//最小值优先 </span></span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,cmp2&gt;que2;<span class="comment">//最大值优先 </span></span><br><span class="line">   </span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,greater&lt;<span class="keyword">int</span>&gt; &gt;que3;<span class="comment">//注意“&gt;&gt;”会被认为错误， </span></span><br><span class="line">                                                      <span class="comment">//这是右移运算符，所以这里用空格号隔开 </span></span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,less&lt;<span class="keyword">int</span>&gt; &gt;que4;<span class="comment">////最大值优先 </span></span><br><span class="line">   </span><br><span class="line">    priority_queue&lt;number1&gt;que5; </span><br><span class="line">    priority_queue&lt;number2&gt;que6; </span><br><span class="line">   </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MATLAB入门笔记</title>
      <link href="/2021/06/08/matlab%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"/>
      <url>/2021/06/08/matlab%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="1-简单函数："><a href="#1-简单函数：" class="headerlink" title="1.简单函数："></a>1.简单函数：</h3><p><strong>1.1 linspace 函数</strong>：</p><p>可以用于产生x1,x2之间的N点行线性的矢量，linspace(x1,x2,N)</p><p>调用方法：linspace(x1,x2,N)</p><p>功 能：用于产生x1，x2之间的N点行矢量，相邻数据跨度相同。其中x1、x2、N分别为起始值、终止值、元素个数。若缺省N，默认点数为100。</p><p><strong>1.2 zeros函数</strong></p><p>zeros(x,y) 生成一个x行y列的矩阵</p><p><strong>1.3.ones函数</strong></p><p>生成所有元素都为1的方阵</p><p><strong>1.4.eye函数</strong></p><p>生成单位向量</p><p><strong>1.5.rand函数</strong></p><p>Ran(x,y) 生成x到y的随机数</p><h3 id="2-字符短语"><a href="#2-字符短语" class="headerlink" title="2.字符短语"></a>2.字符短语</h3><p>pi为派；i表示复数；inf为无穷大；NaN无意义(not a number); clc清屏; clear all 清除所有变量; close all 关闭所有窗口</p><h3 id="3-基本运算符号："><a href="#3-基本运算符号：" class="headerlink" title="3.基本运算符号："></a>3.基本运算符号：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">*为乘号 ；.*为点乘（对应位置相乘）./除号同理 ；加.后为对应位置计算</span><br><span class="line">^阶乘</span><br></pre></td></tr></table></figure><h3 id="4-取出矩阵中的值-amp-amp-赋值："><a href="#4-取出矩阵中的值-amp-amp-赋值：" class="headerlink" title="4.取出矩阵中的值 &amp;&amp; 赋值："></a>4.取出矩阵中的值 &amp;&amp; 赋值：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">A = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> ; <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> ; <span class="number">7</span> <span class="number">8</span> <span class="number">9</span>];</span><br><span class="line">x = A(<span class="number">1</span>,<span class="number">3</span>)   <span class="comment">% 取第一行第三列</span></span><br><span class="line">y = A(<span class="number">2</span>,:)   <span class="comment">% 取第二行全部</span></span><br><span class="line">z = A(<span class="number">1</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>) <span class="comment">%取第一到第二行的第一到第三列</span></span><br><span class="line"></span><br><span class="line">A(<span class="number">1</span>,<span class="number">3</span>) = <span class="number">0</span>   <span class="comment">%给第一行第三列赋值</span></span><br><span class="line">A(<span class="number">2</span>, : ) = [<span class="number">6</span> <span class="number">5</span> <span class="number">4</span>]   <span class="comment">%给第二行赋值</span></span><br><span class="line">A(<span class="number">1</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">2</span>) = [<span class="number">-1</span> <span class="number">-2</span>; <span class="number">-3</span> <span class="number">-4</span>]   <span class="comment">%给第一到第二行的第一到第二列赋值</span></span><br></pre></td></tr></table></figure><h3 id="5-比较和逻辑运算"><a href="#5-比较和逻辑运算" class="headerlink" title="5.比较和逻辑运算"></a>5.比较和逻辑运算</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">eq = (x==y)  <span class="comment">%比较x与y矩阵各个位置大小并按位输出 0 1</span></span><br><span class="line">xy = (x&gt;<span class="number">5</span>)&amp;(y&lt;<span class="number">7</span>) <span class="comment">%判断各个位置是否满足并输出 0 1 &amp;为“与”</span></span><br><span class="line">xoy = (x&gt;<span class="number">5</span>)|(y&lt;<span class="number">7</span>) <span class="comment">%或</span></span><br><span class="line"></span><br><span class="line">x(x&lt;<span class="number">0</span>) = <span class="number">0</span> <span class="comment">%把x中小于0的值赋值为0</span></span><br><span class="line">y(y(:,<span class="number">1</span>)&lt;<span class="number">0</span>,:) = <span class="number">0</span>   <span class="comment">% 先判断该行第一列的值是否&lt;0，若是则将该行赋值为0</span></span><br></pre></td></tr></table></figure><h3 id="6-数组操作函数"><a href="#6-数组操作函数" class="headerlink" title="6.数组操作函数"></a>6.数组操作函数</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">y = <span class="built_in">flipud</span>(x)   <span class="comment">%翻转矩阵 第一行到最后一行 以此类推</span></span><br><span class="line">c = <span class="built_in">rot90</span>(x)    <span class="comment">% 矩阵旋转90度 第一行到第一列</span></span><br><span class="line"></span><br><span class="line">sum(x)   <span class="comment">% 对x中各元素进行求和 若是多行矩阵，则对各列进行求和</span></span><br><span class="line">sum(x,<span class="number">2</span>)  <span class="comment">% 对x中每一行各元素进行求和</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">max</span>(x)  <span class="comment">%求各元素最大值 若是多行矩阵，则求各列最大值</span></span><br><span class="line"><span class="built_in">max</span>(x,<span class="number">2</span>) <span class="comment">%将矩阵中各元素与2进行比较并输出较大的值</span></span><br><span class="line"><span class="built_in">max</span>(x,[],<span class="number">2</span>) <span class="comment">%求各行最大值</span></span><br></pre></td></tr></table></figure><h3 id="7-常用数学函数："><a href="#7-常用数学函数：" class="headerlink" title="7.常用数学函数："></a>7.常用数学函数：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">y = <span class="built_in">abs</span>(x)  <span class="comment">%对矩阵中各个元素求绝对值</span></span><br><span class="line">z = <span class="built_in">sqrt</span>(y)  <span class="comment">%对矩阵中各元素开方</span></span><br><span class="line"><span class="comment">%取整：</span></span><br><span class="line">y = <span class="built_in">ceil</span>(x)  <span class="comment">%向上取整</span></span><br><span class="line">z = <span class="built_in">floor</span>(x)  <span class="comment">%向上取整</span></span><br><span class="line">a = <span class="built_in">fix</span>(x)  <span class="comment">%取整数部分</span></span><br><span class="line">b = <span class="built_in">round</span>(x)  <span class="comment">% 四舍五入</span></span><br></pre></td></tr></table></figure><h3 id="8-基本语句："><a href="#8-基本语句：" class="headerlink" title="8.基本语句："></a>8.基本语句：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> .. <span class="keyword">end</span></span><br><span class="line"><span class="keyword">if</span> .. <span class="keyword">else</span> .. <span class="keyword">end</span></span><br><span class="line"><span class="keyword">while</span> .. <span class="keyword">end</span></span><br><span class="line"><span class="keyword">switch</span> .. <span class="keyword">case</span> .. <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%sum of the odd number between 1 and 10</span></span><br><span class="line">x = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="number">10</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">mod</span>(<span class="built_in">i</span>,<span class="number">2</span>)</span><br><span class="line">x = x + <span class="built_in">i</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="9-二维曲线：sin-amp-cos"><a href="#9-二维曲线：sin-amp-cos" class="headerlink" title="9.二维曲线：sin &amp; cos"></a>9.二维曲线：sin &amp; cos</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="built_in">plot</span>  <span class="comment">%描点画图</span></span><br><span class="line"></span><br><span class="line">x = <span class="number">-2</span>*<span class="built_in">pi</span>:<span class="number">0.1</span>:<span class="number">2</span>*<span class="built_in">pi</span>;  <span class="comment">% -2pi到2pi 步长为0.1</span></span><br><span class="line">y1 = <span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">plot</span>(x,y1,<span class="string">&#x27;-b&#x27;</span>);      <span class="comment">%-表示实线 b表示颜色</span></span><br><span class="line"><span class="built_in">hold</span> on               <span class="comment">%保持现在的图窗 下一个图形也会画在该图上</span></span><br><span class="line"><span class="built_in">plot</span>(x, y2,<span class="string">&#x27;-r&#x27;</span>);</span><br><span class="line"></span><br><span class="line">xlabel(<span class="string">&#x27;x&#x27;</span>);           <span class="comment">%定义坐标名为x</span></span><br><span class="line">ylabel(<span class="string">&#x27;y&#x27;</span>);           <span class="comment">%定义坐标名为y</span></span><br><span class="line">text(<span class="number">0</span>,<span class="number">0</span>, <span class="string">&#x27;(0,0)&#x27;</span>)    <span class="comment">%在坐标(0,0)处显示‘(0,0)’字符</span></span><br><span class="line"><span class="built_in">legend</span>(<span class="string">&#x27;sin x&#x27;</span>,<span class="string">&#x27;cos x&#x27;</span>)    <span class="comment">%图例函数 </span></span><br><span class="line">title(<span class="string">&#x27;sin x and cos x&#x27;</span>)   <span class="comment">%标题</span></span><br><span class="line">axis([<span class="number">-20</span>,<span class="number">20</span>,<span class="number">-20</span>,<span class="number">15</span>]);     <span class="comment">%坐标轴限制 分别为x最小值 x最大值 y最小值 y最大值  </span></span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">%plot用法总结：</span></span><br><span class="line">color: b-blue g-green r-red c-cyan m-megenta y-yellow k-black w-white</span><br><span class="line">grid on <span class="comment">%加网格线   </span></span><br><span class="line">grid minor <span class="comment">%网格线变得更密</span></span><br><span class="line">xlim([xmin,xmax]) or ylim([ymin,ymax]);  <span class="comment">%单独限制x or y坐标范围</span></span><br></pre></td></tr></table></figure><h3 id="10-二维曲线：对数和极坐标系"><a href="#10-二维曲线：对数和极坐标系" class="headerlink" title="10.二维曲线：对数和极坐标系"></a>10.二维曲线：对数和极坐标系</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">loglog(x,y,<span class="string">&#x27;-r&#x27;</span>)   <span class="comment">%x和y轴都为对数坐标</span></span><br><span class="line">semilogx(x,y,<span class="string">&#x27;-r&#x27;</span>)   <span class="comment">%x轴是对数坐标系 semilogy同理</span></span><br><span class="line">y = <span class="built_in">exp</span>(x)         <span class="comment">%对数函数 值为e^x</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%极坐标系</span></span><br><span class="line">theta = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">180</span>:<span class="number">4</span>*<span class="built_in">pi</span>  <span class="comment">%定角度</span></span><br><span class="line">r = <span class="number">1</span>-<span class="built_in">sin</span>(theta);</span><br><span class="line">polar(theta,r,<span class="string">&#x27;-r&#x27;</span>);    <span class="comment">%绘制极坐标系图</span></span><br></pre></td></tr></table></figure><h3 id="11-二维填充："><a href="#11-二维填充：" class="headerlink" title="11.二维填充："></a>11.二维填充：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x = [<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>];</span><br><span class="line">y = [<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">-1</span>];</span><br><span class="line">h = fill(x,y,<span class="string">&#x27;-r&#x27;</span>);   <span class="comment">%利用fill函数进行填充</span></span><br><span class="line">xc = [<span class="number">-2</span> <span class="number">2</span>]; yc = [<span class="number">-2</span> <span class="number">2</span>];</span><br><span class="line">x = [xc<span class="number">-1</span>; xc<span class="number">-1</span>; xc+<span class="number">1</span>; xc+<span class="number">1</span>]</span><br><span class="line">y = [yc<span class="number">-1</span>; yc+<span class="number">1</span>; yc+<span class="number">1</span>; yc<span class="number">-1</span>]</span><br><span class="line">h = fill(x, y, <span class="string">&#x27;b&#x27;</span>);     <span class="comment">%按列的顺序绘制多个图形</span></span><br><span class="line">set(h(<span class="number">1</span>),<span class="string">&#x27;FaceColor&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)             <span class="comment">%指定单个图形的颜色 1为第一个出现的图形</span></span><br><span class="line">set(h(<span class="number">2</span>),<span class="string">&#x27;xdata&#x27;</span>,x(:,<span class="number">2</span>)<span class="number">-2</span>)      <span class="comment">%需改单个图形的值 此处为修改第二个图形的x坐标</span></span><br></pre></td></tr></table></figure><h3 id="12-数组显示："><a href="#12-数组显示：" class="headerlink" title="12.数组显示："></a>12.数组显示：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">x = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>; <span class="number">4</span> <span class="number">5</span> <span class="number">6</span>;<span class="number">7</span> <span class="number">8</span> <span class="number">9</span>];</span><br><span class="line">imagesc(x);             <span class="comment">%将数组用图形画出来</span></span><br></pre></td></tr></table></figure><h3 id="13-三维曲线："><a href="#13-三维曲线：" class="headerlink" title="13.三维曲线："></a>13.三维曲线：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">t = <span class="number">0</span>:<span class="built_in">pi</span>/<span class="number">50</span>:<span class="number">10</span>*<span class="built_in">pi</span>;</span><br><span class="line">x = <span class="built_in">sin</span>(t);</span><br><span class="line">y = <span class="built_in">cos</span>(t);</span><br><span class="line">z = t;</span><br><span class="line"><span class="built_in">plot3</span>(x,y,z)</span><br><span class="line"></span><br><span class="line">title(<span class="string">&#x27;Helix&#x27;</span>)</span><br><span class="line">xlabel(<span class="string">&#x27;sin t&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;cos t&#x27;</span>)</span><br><span class="line">zlabel(<span class="string">&#x27;t&#x27;</span>)</span><br><span class="line">grid on </span><br></pre></td></tr></table></figure><h3 id="14-三维曲面："><a href="#14-三维曲面：" class="headerlink" title="14.三维曲面："></a>14.三维曲面：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="built_in">meshgrid</span>()    <span class="comment">%生成网格矩阵</span></span><br><span class="line">[x , y] = <span class="built_in">meshgrid</span>(<span class="number">1</span>:<span class="number">3</span>, <span class="number">1</span>:<span class="number">3</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">%生成sinxcosy</span></span><br><span class="line">[x,y] = <span class="built_in">meshgrid</span>(-<span class="built_in">pi</span>:<span class="number">0.1</span>:<span class="built_in">pi</span>);</span><br><span class="line">z = <span class="built_in">sin</span>(x).*<span class="built_in">cos</span>(y);</span><br><span class="line">mesh(x,y,z)   <span class="comment">%meshc()可投影到底面</span></span><br><span class="line">surf(x,y,z)   <span class="comment">%surfc()可投影到底面</span></span><br><span class="line">xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">zlabel(<span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">title(<span class="string">&#x27;sin x sin y&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="15-函数："><a href="#15-函数：" class="headerlink" title="15.函数："></a>15.函数：</h3><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span><span class="params">[output1, ..]</span> = <span class="title">functionname</span><span class="params">(input1, ..)</span></span></span><br><span class="line"><span class="comment">% comment of this function</span></span><br><span class="line">Matlab command <span class="number">1</span>;</span><br><span class="line">Matlab command <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">%example</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[s]</span> = <span class="title">areamath</span><span class="params">(w,l)</span></span></span><br><span class="line">s = w.*l;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MATLAB </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
